{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90b38a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import net_size_utils as nsu\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, kernel_size=5):\n",
    "        super().__init__()\n",
    "        self.kernel_size = kernel_size\n",
    "        self.conv1 = nn.Conv2d(3, 6, kernel_size)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, kernel_size)\n",
    "        conv_height, conv_width = self.conv_out_size(224, 224)\n",
    "        linear_input_size = 16 * conv_width * conv_height\n",
    "        self.fc1 = nn.Linear(linear_input_size, 120)\n",
    "        self.fc2 = nn.Linear(120, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "    def conv_out_size(self, height, width):\n",
    "        dim = (height, width)\n",
    "        dim = nsu.dim_conv2d(dim, self.kernel_size)\n",
    "        dim = nsu.dim_maxpool2d(dim, 2, 2)\n",
    "        dim = nsu.dim_conv2d(dim, self.kernel_size)\n",
    "        dim = nsu.dim_maxpool2d(dim, 2, 2)\n",
    "        return dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2e73ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics\n",
    "import torch.utils.data as td\n",
    "import net_training\n",
    "from birds_dataset import Birds270Dataset\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import pandas as pd\n",
    "\n",
    "# Splits a dataset randomly into a train and test set. The size of test set is 80% of the whole dataset.\n",
    "# Then it trains the network\n",
    "def train_net_random_dataset_split(net, dataset, epochs, optimizer, batch_size):\n",
    "    train_set_size = int(len(dataset)*0.8)\n",
    "    test_set_size = len(dataset)-train_set_size\n",
    "    train_dataset, test_dataset = td.random_split(dataset, [train_set_size, test_set_size])\n",
    "    label_set = dataset.get_label_set()\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size, shuffle=True)\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size, shuffle=True)\n",
    "    results = net_training.train_and_evaluate(net, train_dataloader, test_dataloader, label_set,\n",
    "                                 epochs=epochs, optimizer=optimizer, print_results=False)\n",
    "    return results\n",
    "\n",
    "# Creates a few networks and trains them using a random split of the dataset.\n",
    "# The number of created networks is in the \"repeat\" argument\n",
    "# It returns the final validation results for each network\n",
    "def cross_validate_net(net_generator, dataset, repeat=5, epochs=20, optimizer=None, batch_size=32):\n",
    "    all_results = []\n",
    "    for i in range(repeat):\n",
    "        print(f\"Training network {i+1} ...\")\n",
    "        net = net_generator()\n",
    "        results = train_net_random_dataset_split(net, dataset, epochs, optimizer, batch_size=32)\n",
    "        all_results.append(results)\n",
    "        net_training.print_final_results(results)\n",
    "    return all_results\n",
    "    \n",
    "    \n",
    "def print_validation_results(cross_validation_results):\n",
    "    losses = [r[\"loss\"] for r in cross_validation_results]\n",
    "    accuracies = [r[\"accuracy\"] for r in cross_validation_results]\n",
    "    print(\"Losses: \", losses)\n",
    "    print(\"Loss:  mean: {:.4f}, std: {:.4f}\".format(statistics.mean(losses), statistics.stdev(losses)))\n",
    "    print(\"Accuracies: \", accuracies)\n",
    "    print(\"Accuracy:  mean: {:.4f}, std: {:.4f}\".format(statistics.mean(accuracies), statistics.stdev(accuracies)))\n",
    "    \n",
    "def results_to_dataframe(cross_validation_results):\n",
    "    normalized = pd.json_normalize(cross_validation_results)\n",
    "    return normalized\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44012fb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training network 1 ...\n",
      "Final loss: 1.1769, final accuracy: 73.63 %\n",
      "\tALBATROSS: 51.72%\n",
      "\tBALD EAGLE: 73.33%\n",
      "\tBARN OWL: 81.48%\n",
      "\tEURASIAN MAGPIE: 80.00%\n",
      "\tFLAMINGO: 73.91%\n",
      "\tMALLARD DUCK: 87.50%\n",
      "\tOSTRICH: 69.23%\n",
      "\tPEACOCK: 89.47%\n",
      "\tPELICAN: 35.00%\n",
      "\tTRUMPTER SWAN: 80.00%\n",
      "Training network 2 ...\n",
      "Final loss: 1.5047, final accuracy: 70.55 %\n",
      "\tALBATROSS: 67.86%\n",
      "\tBALD EAGLE: 85.29%\n",
      "\tBARN OWL: 62.50%\n",
      "\tEURASIAN MAGPIE: 82.86%\n",
      "\tFLAMINGO: 77.27%\n",
      "\tMALLARD DUCK: 64.29%\n",
      "\tOSTRICH: 73.33%\n",
      "\tPEACOCK: 87.10%\n",
      "\tPELICAN: 31.82%\n",
      "\tTRUMPTER SWAN: 60.53%\n",
      "Training network 3 ...\n",
      "Final loss: 1.5142, final accuracy: 67.12 %\n",
      "\tALBATROSS: 50.00%\n",
      "\tBALD EAGLE: 64.29%\n",
      "\tBARN OWL: 73.68%\n",
      "\tEURASIAN MAGPIE: 68.42%\n",
      "\tFLAMINGO: 82.86%\n",
      "\tMALLARD DUCK: 65.38%\n",
      "\tOSTRICH: 80.00%\n",
      "\tPEACOCK: 77.50%\n",
      "\tPELICAN: 40.91%\n",
      "\tTRUMPTER SWAN: 57.69%\n",
      "Losses:  [1.1768746571998074, 1.5046706656887108, 1.5141913515247711]\n",
      "Loss:  mean: 1.3986, std: 0.1921\n",
      "Accuracies:  [0.7363013698630136, 0.7054794520547946, 0.6712328767123288]\n",
      "Accuracy:  mean: 0.7043, std: 0.0325\n"
     ]
    }
   ],
   "source": [
    "dataset_dir = \"../data/birds270\"\n",
    "selected_birds = [\"ALBATROSS\", \"BALD EAGLE\", \"BARN OWL\", \"EURASIAN MAGPIE\", \"FLAMINGO\",\n",
    "                  \"MALLARD DUCK\", \"OSTRICH\", \"PEACOCK\", \"PELICAN\", \"TRUMPTER SWAN\"]\n",
    "\n",
    "transform = transforms.Normalize((127.5, 127.5, 127.5), (127.5, 127.5, 127.5)) # normalizes colors to range [-1,1]\n",
    "dataset = Birds270Dataset(dataset_dir,  selected_birds=selected_birds, transform=transform)\n",
    "\n",
    "results = cross_validate_net(Net, dataset, repeat=3, epochs=100)\n",
    "print_validation_results(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a338172",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = results_to_dataframe(results)\n",
    "dataframe.to_csv(\"../results/test1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1547d404",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
