{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "626897ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_parameter_requires_grad(model, feature_extracting):\n",
    "    if feature_extracting:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "def get_params_to_update(net, feature_extract):\n",
    "    params_to_update = net.parameters()\n",
    "    print(\"Params to learn:\")\n",
    "    if feature_extract:\n",
    "        params_to_update = []\n",
    "        for name,param in net.named_parameters():\n",
    "            if param.requires_grad == True:\n",
    "                params_to_update.append(param)\n",
    "                print(\"\\t\",name)\n",
    "    else:\n",
    "        for name,param in net.named_parameters():\n",
    "            if param.requires_grad == True:\n",
    "                print(\"\\t\",name)\n",
    "    return params_to_update\n",
    "\n",
    "def make_alexnet(out_features, feature_extract = False):\n",
    "    net = models.alexnet(pretrained=True)\n",
    "    set_parameter_requires_grad(net, feature_extract)\n",
    "    num_ftrs = net.classifier[6].in_features\n",
    "    net.classifier[6] = nn.Linear(num_ftrs, out_features)\n",
    "    params_to_update = get_params_to_update(net, feature_extract)\n",
    "    optimizer = optim.Adam(params_to_update, lr=0.0001)\n",
    "    return net, optimizer\n",
    "\n",
    "def make_mobilenet_v3(out_features, feature_extract = False):\n",
    "    net = models.mobilenet_v3_small(pretrained=True)\n",
    "    set_parameter_requires_grad(net, feature_extract)\n",
    "    num_ftrs = net.classifier[3].in_features\n",
    "    net.classifier[3] = nn.Linear(num_ftrs, out_features)\n",
    "    params_to_update = get_params_to_update(net, feature_extract)\n",
    "    optimizer = optim.Adam(params_to_update, lr=0.0001)\n",
    "    return net, optimizer\n",
    "\n",
    "def make_inception_v3(out_features, feature_extract = False):\n",
    "    net = models.inception_v3(pretrained=True)\n",
    "    set_parameter_requires_grad(net, feature_extract)\n",
    "    num_ftrs = net.AuxLogits.fc.in_features\n",
    "    net.AuxLogits.fc = nn.Linear(num_ftrs, out_features)\n",
    "    num_ftrs = net.fc.in_features\n",
    "    net.fc = nn.Linear(num_ftrs, out_features)\n",
    "    params_to_update = get_params_to_update(net, feature_extract)\n",
    "    optimizer = optim.Adam(params_to_update, lr=0.0001)\n",
    "    return net, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2e73ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics\n",
    "import torch.utils.data as td\n",
    "import net_training\n",
    "from birds_dataset import Birds270Dataset\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets, models\n",
    "import pandas as pd\n",
    "\n",
    "# Splits a dataset randomly into a train and test set. The size of test set is 80% of the whole dataset.\n",
    "# Then it trains the network\n",
    "def train_net_random_dataset_split(net, dataset, epochs, optimizer, batch_size, early_stopping, is_inception):\n",
    "    train_set_size = int(len(dataset)*0.8)\n",
    "    test_set_size = len(dataset)-train_set_size\n",
    "    train_dataset, test_dataset = td.random_split(dataset, [train_set_size, test_set_size])\n",
    "    label_set = dataset.get_label_set()\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size, shuffle=True)\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size, shuffle=True)\n",
    "    device = None # Wybiera CUDA jeśli jest dostępne, w przeciwnym wypadku CPU\n",
    "    # device = \"cpu\" # Odkomentować jeżeli CUDA nie będzie działać\n",
    "    results = net_training.train_and_evaluate(net, train_dataloader, test_dataloader, label_set,early_stopping = early_stopping,\n",
    "                                 epochs=epochs, optimizer=optimizer, print_results=True, device=device, is_inception=is_inception)\n",
    "    return results\n",
    "\n",
    "# Creates a few networks and trains them using a random split of the dataset.\n",
    "# The number of created networks is in the \"repeat\" argument\n",
    "# It returns the final validation results for each network\n",
    "def cross_validate_net(net_generator, dataset, repeat=5, epochs=20, batch_size=32, is_inception=False):\n",
    "    all_results = []\n",
    "    for i in range(repeat):\n",
    "        print(f\"Training network {i+1} ...\")\n",
    "        net, optimizer = net_generator()\n",
    "        early_stopping = net_training.EarlyStoppingByAccuracy(patience=10)\n",
    "        results = train_net_random_dataset_split(net, dataset, epochs,optimizer=optimizer,\n",
    "                                                 early_stopping=early_stopping, batch_size=batch_size, is_inception=is_inception)\n",
    "        all_results.append(results)\n",
    "        net_training.print_final_results(results)\n",
    "        del optimizer, net\n",
    "        torch.cuda.empty_cache()\n",
    "    return all_results\n",
    "    \n",
    "    \n",
    "def print_validation_results(cross_validation_results):\n",
    "    losses = [r[\"loss\"] for r in cross_validation_results]\n",
    "    accuracies = [r[\"accuracy\"] for r in cross_validation_results]\n",
    "    print(\"Losses: \", losses)\n",
    "    print(\"Loss:  mean: {:.4f}, std: {:.4f}\".format(statistics.mean(losses), statistics.stdev(losses)))\n",
    "    print(\"Accuracies: \", accuracies)\n",
    "    print(\"Accuracy:  mean: {:.4f}, std: {:.4f}\".format(statistics.mean(accuracies), statistics.stdev(accuracies)))\n",
    "    \n",
    "def results_to_dataframe(cross_validation_results):\n",
    "    normalized = pd.json_normalize(cross_validation_results)\n",
    "    return normalized\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44012fb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training network 1 ...\n",
      "Params to learn:\n",
      "\t Conv2d_1a_3x3.conv.weight\n",
      "\t Conv2d_1a_3x3.bn.weight\n",
      "\t Conv2d_1a_3x3.bn.bias\n",
      "\t Conv2d_2a_3x3.conv.weight\n",
      "\t Conv2d_2a_3x3.bn.weight\n",
      "\t Conv2d_2a_3x3.bn.bias\n",
      "\t Conv2d_2b_3x3.conv.weight\n",
      "\t Conv2d_2b_3x3.bn.weight\n",
      "\t Conv2d_2b_3x3.bn.bias\n",
      "\t Conv2d_3b_1x1.conv.weight\n",
      "\t Conv2d_3b_1x1.bn.weight\n",
      "\t Conv2d_3b_1x1.bn.bias\n",
      "\t Conv2d_4a_3x3.conv.weight\n",
      "\t Conv2d_4a_3x3.bn.weight\n",
      "\t Conv2d_4a_3x3.bn.bias\n",
      "\t Mixed_5b.branch1x1.conv.weight\n",
      "\t Mixed_5b.branch1x1.bn.weight\n",
      "\t Mixed_5b.branch1x1.bn.bias\n",
      "\t Mixed_5b.branch5x5_1.conv.weight\n",
      "\t Mixed_5b.branch5x5_1.bn.weight\n",
      "\t Mixed_5b.branch5x5_1.bn.bias\n",
      "\t Mixed_5b.branch5x5_2.conv.weight\n",
      "\t Mixed_5b.branch5x5_2.bn.weight\n",
      "\t Mixed_5b.branch5x5_2.bn.bias\n",
      "\t Mixed_5b.branch3x3dbl_1.conv.weight\n",
      "\t Mixed_5b.branch3x3dbl_1.bn.weight\n",
      "\t Mixed_5b.branch3x3dbl_1.bn.bias\n",
      "\t Mixed_5b.branch3x3dbl_2.conv.weight\n",
      "\t Mixed_5b.branch3x3dbl_2.bn.weight\n",
      "\t Mixed_5b.branch3x3dbl_2.bn.bias\n",
      "\t Mixed_5b.branch3x3dbl_3.conv.weight\n",
      "\t Mixed_5b.branch3x3dbl_3.bn.weight\n",
      "\t Mixed_5b.branch3x3dbl_3.bn.bias\n",
      "\t Mixed_5b.branch_pool.conv.weight\n",
      "\t Mixed_5b.branch_pool.bn.weight\n",
      "\t Mixed_5b.branch_pool.bn.bias\n",
      "\t Mixed_5c.branch1x1.conv.weight\n",
      "\t Mixed_5c.branch1x1.bn.weight\n",
      "\t Mixed_5c.branch1x1.bn.bias\n",
      "\t Mixed_5c.branch5x5_1.conv.weight\n",
      "\t Mixed_5c.branch5x5_1.bn.weight\n",
      "\t Mixed_5c.branch5x5_1.bn.bias\n",
      "\t Mixed_5c.branch5x5_2.conv.weight\n",
      "\t Mixed_5c.branch5x5_2.bn.weight\n",
      "\t Mixed_5c.branch5x5_2.bn.bias\n",
      "\t Mixed_5c.branch3x3dbl_1.conv.weight\n",
      "\t Mixed_5c.branch3x3dbl_1.bn.weight\n",
      "\t Mixed_5c.branch3x3dbl_1.bn.bias\n",
      "\t Mixed_5c.branch3x3dbl_2.conv.weight\n",
      "\t Mixed_5c.branch3x3dbl_2.bn.weight\n",
      "\t Mixed_5c.branch3x3dbl_2.bn.bias\n",
      "\t Mixed_5c.branch3x3dbl_3.conv.weight\n",
      "\t Mixed_5c.branch3x3dbl_3.bn.weight\n",
      "\t Mixed_5c.branch3x3dbl_3.bn.bias\n",
      "\t Mixed_5c.branch_pool.conv.weight\n",
      "\t Mixed_5c.branch_pool.bn.weight\n",
      "\t Mixed_5c.branch_pool.bn.bias\n",
      "\t Mixed_5d.branch1x1.conv.weight\n",
      "\t Mixed_5d.branch1x1.bn.weight\n",
      "\t Mixed_5d.branch1x1.bn.bias\n",
      "\t Mixed_5d.branch5x5_1.conv.weight\n",
      "\t Mixed_5d.branch5x5_1.bn.weight\n",
      "\t Mixed_5d.branch5x5_1.bn.bias\n",
      "\t Mixed_5d.branch5x5_2.conv.weight\n",
      "\t Mixed_5d.branch5x5_2.bn.weight\n",
      "\t Mixed_5d.branch5x5_2.bn.bias\n",
      "\t Mixed_5d.branch3x3dbl_1.conv.weight\n",
      "\t Mixed_5d.branch3x3dbl_1.bn.weight\n",
      "\t Mixed_5d.branch3x3dbl_1.bn.bias\n",
      "\t Mixed_5d.branch3x3dbl_2.conv.weight\n",
      "\t Mixed_5d.branch3x3dbl_2.bn.weight\n",
      "\t Mixed_5d.branch3x3dbl_2.bn.bias\n",
      "\t Mixed_5d.branch3x3dbl_3.conv.weight\n",
      "\t Mixed_5d.branch3x3dbl_3.bn.weight\n",
      "\t Mixed_5d.branch3x3dbl_3.bn.bias\n",
      "\t Mixed_5d.branch_pool.conv.weight\n",
      "\t Mixed_5d.branch_pool.bn.weight\n",
      "\t Mixed_5d.branch_pool.bn.bias\n",
      "\t Mixed_6a.branch3x3.conv.weight\n",
      "\t Mixed_6a.branch3x3.bn.weight\n",
      "\t Mixed_6a.branch3x3.bn.bias\n",
      "\t Mixed_6a.branch3x3dbl_1.conv.weight\n",
      "\t Mixed_6a.branch3x3dbl_1.bn.weight\n",
      "\t Mixed_6a.branch3x3dbl_1.bn.bias\n",
      "\t Mixed_6a.branch3x3dbl_2.conv.weight\n",
      "\t Mixed_6a.branch3x3dbl_2.bn.weight\n",
      "\t Mixed_6a.branch3x3dbl_2.bn.bias\n",
      "\t Mixed_6a.branch3x3dbl_3.conv.weight\n",
      "\t Mixed_6a.branch3x3dbl_3.bn.weight\n",
      "\t Mixed_6a.branch3x3dbl_3.bn.bias\n",
      "\t Mixed_6b.branch1x1.conv.weight\n",
      "\t Mixed_6b.branch1x1.bn.weight\n",
      "\t Mixed_6b.branch1x1.bn.bias\n",
      "\t Mixed_6b.branch7x7_1.conv.weight\n",
      "\t Mixed_6b.branch7x7_1.bn.weight\n",
      "\t Mixed_6b.branch7x7_1.bn.bias\n",
      "\t Mixed_6b.branch7x7_2.conv.weight\n",
      "\t Mixed_6b.branch7x7_2.bn.weight\n",
      "\t Mixed_6b.branch7x7_2.bn.bias\n",
      "\t Mixed_6b.branch7x7_3.conv.weight\n",
      "\t Mixed_6b.branch7x7_3.bn.weight\n",
      "\t Mixed_6b.branch7x7_3.bn.bias\n",
      "\t Mixed_6b.branch7x7dbl_1.conv.weight\n",
      "\t Mixed_6b.branch7x7dbl_1.bn.weight\n",
      "\t Mixed_6b.branch7x7dbl_1.bn.bias\n",
      "\t Mixed_6b.branch7x7dbl_2.conv.weight\n",
      "\t Mixed_6b.branch7x7dbl_2.bn.weight\n",
      "\t Mixed_6b.branch7x7dbl_2.bn.bias\n",
      "\t Mixed_6b.branch7x7dbl_3.conv.weight\n",
      "\t Mixed_6b.branch7x7dbl_3.bn.weight\n",
      "\t Mixed_6b.branch7x7dbl_3.bn.bias\n",
      "\t Mixed_6b.branch7x7dbl_4.conv.weight\n",
      "\t Mixed_6b.branch7x7dbl_4.bn.weight\n",
      "\t Mixed_6b.branch7x7dbl_4.bn.bias\n",
      "\t Mixed_6b.branch7x7dbl_5.conv.weight\n",
      "\t Mixed_6b.branch7x7dbl_5.bn.weight\n",
      "\t Mixed_6b.branch7x7dbl_5.bn.bias\n",
      "\t Mixed_6b.branch_pool.conv.weight\n",
      "\t Mixed_6b.branch_pool.bn.weight\n",
      "\t Mixed_6b.branch_pool.bn.bias\n",
      "\t Mixed_6c.branch1x1.conv.weight\n",
      "\t Mixed_6c.branch1x1.bn.weight\n",
      "\t Mixed_6c.branch1x1.bn.bias\n",
      "\t Mixed_6c.branch7x7_1.conv.weight\n",
      "\t Mixed_6c.branch7x7_1.bn.weight\n",
      "\t Mixed_6c.branch7x7_1.bn.bias\n",
      "\t Mixed_6c.branch7x7_2.conv.weight\n",
      "\t Mixed_6c.branch7x7_2.bn.weight\n",
      "\t Mixed_6c.branch7x7_2.bn.bias\n",
      "\t Mixed_6c.branch7x7_3.conv.weight\n",
      "\t Mixed_6c.branch7x7_3.bn.weight\n",
      "\t Mixed_6c.branch7x7_3.bn.bias\n",
      "\t Mixed_6c.branch7x7dbl_1.conv.weight\n",
      "\t Mixed_6c.branch7x7dbl_1.bn.weight\n",
      "\t Mixed_6c.branch7x7dbl_1.bn.bias\n",
      "\t Mixed_6c.branch7x7dbl_2.conv.weight\n",
      "\t Mixed_6c.branch7x7dbl_2.bn.weight\n",
      "\t Mixed_6c.branch7x7dbl_2.bn.bias\n",
      "\t Mixed_6c.branch7x7dbl_3.conv.weight\n",
      "\t Mixed_6c.branch7x7dbl_3.bn.weight\n",
      "\t Mixed_6c.branch7x7dbl_3.bn.bias\n",
      "\t Mixed_6c.branch7x7dbl_4.conv.weight\n",
      "\t Mixed_6c.branch7x7dbl_4.bn.weight\n",
      "\t Mixed_6c.branch7x7dbl_4.bn.bias\n",
      "\t Mixed_6c.branch7x7dbl_5.conv.weight\n",
      "\t Mixed_6c.branch7x7dbl_5.bn.weight\n",
      "\t Mixed_6c.branch7x7dbl_5.bn.bias\n",
      "\t Mixed_6c.branch_pool.conv.weight\n",
      "\t Mixed_6c.branch_pool.bn.weight\n",
      "\t Mixed_6c.branch_pool.bn.bias\n",
      "\t Mixed_6d.branch1x1.conv.weight\n",
      "\t Mixed_6d.branch1x1.bn.weight\n",
      "\t Mixed_6d.branch1x1.bn.bias\n",
      "\t Mixed_6d.branch7x7_1.conv.weight\n",
      "\t Mixed_6d.branch7x7_1.bn.weight\n",
      "\t Mixed_6d.branch7x7_1.bn.bias\n",
      "\t Mixed_6d.branch7x7_2.conv.weight\n",
      "\t Mixed_6d.branch7x7_2.bn.weight\n",
      "\t Mixed_6d.branch7x7_2.bn.bias\n",
      "\t Mixed_6d.branch7x7_3.conv.weight\n",
      "\t Mixed_6d.branch7x7_3.bn.weight\n",
      "\t Mixed_6d.branch7x7_3.bn.bias\n",
      "\t Mixed_6d.branch7x7dbl_1.conv.weight\n",
      "\t Mixed_6d.branch7x7dbl_1.bn.weight\n",
      "\t Mixed_6d.branch7x7dbl_1.bn.bias\n",
      "\t Mixed_6d.branch7x7dbl_2.conv.weight\n",
      "\t Mixed_6d.branch7x7dbl_2.bn.weight\n",
      "\t Mixed_6d.branch7x7dbl_2.bn.bias\n",
      "\t Mixed_6d.branch7x7dbl_3.conv.weight\n",
      "\t Mixed_6d.branch7x7dbl_3.bn.weight\n",
      "\t Mixed_6d.branch7x7dbl_3.bn.bias\n",
      "\t Mixed_6d.branch7x7dbl_4.conv.weight\n",
      "\t Mixed_6d.branch7x7dbl_4.bn.weight\n",
      "\t Mixed_6d.branch7x7dbl_4.bn.bias\n",
      "\t Mixed_6d.branch7x7dbl_5.conv.weight\n",
      "\t Mixed_6d.branch7x7dbl_5.bn.weight\n",
      "\t Mixed_6d.branch7x7dbl_5.bn.bias\n",
      "\t Mixed_6d.branch_pool.conv.weight\n",
      "\t Mixed_6d.branch_pool.bn.weight\n",
      "\t Mixed_6d.branch_pool.bn.bias\n",
      "\t Mixed_6e.branch1x1.conv.weight\n",
      "\t Mixed_6e.branch1x1.bn.weight\n",
      "\t Mixed_6e.branch1x1.bn.bias\n",
      "\t Mixed_6e.branch7x7_1.conv.weight\n",
      "\t Mixed_6e.branch7x7_1.bn.weight\n",
      "\t Mixed_6e.branch7x7_1.bn.bias\n",
      "\t Mixed_6e.branch7x7_2.conv.weight\n",
      "\t Mixed_6e.branch7x7_2.bn.weight\n",
      "\t Mixed_6e.branch7x7_2.bn.bias\n",
      "\t Mixed_6e.branch7x7_3.conv.weight\n",
      "\t Mixed_6e.branch7x7_3.bn.weight\n",
      "\t Mixed_6e.branch7x7_3.bn.bias\n",
      "\t Mixed_6e.branch7x7dbl_1.conv.weight\n",
      "\t Mixed_6e.branch7x7dbl_1.bn.weight\n",
      "\t Mixed_6e.branch7x7dbl_1.bn.bias\n",
      "\t Mixed_6e.branch7x7dbl_2.conv.weight\n",
      "\t Mixed_6e.branch7x7dbl_2.bn.weight\n",
      "\t Mixed_6e.branch7x7dbl_2.bn.bias\n",
      "\t Mixed_6e.branch7x7dbl_3.conv.weight\n",
      "\t Mixed_6e.branch7x7dbl_3.bn.weight\n",
      "\t Mixed_6e.branch7x7dbl_3.bn.bias\n",
      "\t Mixed_6e.branch7x7dbl_4.conv.weight\n",
      "\t Mixed_6e.branch7x7dbl_4.bn.weight\n",
      "\t Mixed_6e.branch7x7dbl_4.bn.bias\n",
      "\t Mixed_6e.branch7x7dbl_5.conv.weight\n",
      "\t Mixed_6e.branch7x7dbl_5.bn.weight\n",
      "\t Mixed_6e.branch7x7dbl_5.bn.bias\n",
      "\t Mixed_6e.branch_pool.conv.weight\n",
      "\t Mixed_6e.branch_pool.bn.weight\n",
      "\t Mixed_6e.branch_pool.bn.bias\n",
      "\t AuxLogits.conv0.conv.weight\n",
      "\t AuxLogits.conv0.bn.weight\n",
      "\t AuxLogits.conv0.bn.bias\n",
      "\t AuxLogits.conv1.conv.weight\n",
      "\t AuxLogits.conv1.bn.weight\n",
      "\t AuxLogits.conv1.bn.bias\n",
      "\t AuxLogits.fc.weight\n",
      "\t AuxLogits.fc.bias\n",
      "\t Mixed_7a.branch3x3_1.conv.weight\n",
      "\t Mixed_7a.branch3x3_1.bn.weight\n",
      "\t Mixed_7a.branch3x3_1.bn.bias\n",
      "\t Mixed_7a.branch3x3_2.conv.weight\n",
      "\t Mixed_7a.branch3x3_2.bn.weight\n",
      "\t Mixed_7a.branch3x3_2.bn.bias\n",
      "\t Mixed_7a.branch7x7x3_1.conv.weight\n",
      "\t Mixed_7a.branch7x7x3_1.bn.weight\n",
      "\t Mixed_7a.branch7x7x3_1.bn.bias\n",
      "\t Mixed_7a.branch7x7x3_2.conv.weight\n",
      "\t Mixed_7a.branch7x7x3_2.bn.weight\n",
      "\t Mixed_7a.branch7x7x3_2.bn.bias\n",
      "\t Mixed_7a.branch7x7x3_3.conv.weight\n",
      "\t Mixed_7a.branch7x7x3_3.bn.weight\n",
      "\t Mixed_7a.branch7x7x3_3.bn.bias\n",
      "\t Mixed_7a.branch7x7x3_4.conv.weight\n",
      "\t Mixed_7a.branch7x7x3_4.bn.weight\n",
      "\t Mixed_7a.branch7x7x3_4.bn.bias\n",
      "\t Mixed_7b.branch1x1.conv.weight\n",
      "\t Mixed_7b.branch1x1.bn.weight\n",
      "\t Mixed_7b.branch1x1.bn.bias\n",
      "\t Mixed_7b.branch3x3_1.conv.weight\n",
      "\t Mixed_7b.branch3x3_1.bn.weight\n",
      "\t Mixed_7b.branch3x3_1.bn.bias\n",
      "\t Mixed_7b.branch3x3_2a.conv.weight\n",
      "\t Mixed_7b.branch3x3_2a.bn.weight\n",
      "\t Mixed_7b.branch3x3_2a.bn.bias\n",
      "\t Mixed_7b.branch3x3_2b.conv.weight\n",
      "\t Mixed_7b.branch3x3_2b.bn.weight\n",
      "\t Mixed_7b.branch3x3_2b.bn.bias\n",
      "\t Mixed_7b.branch3x3dbl_1.conv.weight\n",
      "\t Mixed_7b.branch3x3dbl_1.bn.weight\n",
      "\t Mixed_7b.branch3x3dbl_1.bn.bias\n",
      "\t Mixed_7b.branch3x3dbl_2.conv.weight\n",
      "\t Mixed_7b.branch3x3dbl_2.bn.weight\n",
      "\t Mixed_7b.branch3x3dbl_2.bn.bias\n",
      "\t Mixed_7b.branch3x3dbl_3a.conv.weight\n",
      "\t Mixed_7b.branch3x3dbl_3a.bn.weight\n",
      "\t Mixed_7b.branch3x3dbl_3a.bn.bias\n",
      "\t Mixed_7b.branch3x3dbl_3b.conv.weight\n",
      "\t Mixed_7b.branch3x3dbl_3b.bn.weight\n",
      "\t Mixed_7b.branch3x3dbl_3b.bn.bias\n",
      "\t Mixed_7b.branch_pool.conv.weight\n",
      "\t Mixed_7b.branch_pool.bn.weight\n",
      "\t Mixed_7b.branch_pool.bn.bias\n",
      "\t Mixed_7c.branch1x1.conv.weight\n",
      "\t Mixed_7c.branch1x1.bn.weight\n",
      "\t Mixed_7c.branch1x1.bn.bias\n",
      "\t Mixed_7c.branch3x3_1.conv.weight\n",
      "\t Mixed_7c.branch3x3_1.bn.weight\n",
      "\t Mixed_7c.branch3x3_1.bn.bias\n",
      "\t Mixed_7c.branch3x3_2a.conv.weight\n",
      "\t Mixed_7c.branch3x3_2a.bn.weight\n",
      "\t Mixed_7c.branch3x3_2a.bn.bias\n",
      "\t Mixed_7c.branch3x3_2b.conv.weight\n",
      "\t Mixed_7c.branch3x3_2b.bn.weight\n",
      "\t Mixed_7c.branch3x3_2b.bn.bias\n",
      "\t Mixed_7c.branch3x3dbl_1.conv.weight\n",
      "\t Mixed_7c.branch3x3dbl_1.bn.weight\n",
      "\t Mixed_7c.branch3x3dbl_1.bn.bias\n",
      "\t Mixed_7c.branch3x3dbl_2.conv.weight\n",
      "\t Mixed_7c.branch3x3dbl_2.bn.weight\n",
      "\t Mixed_7c.branch3x3dbl_2.bn.bias\n",
      "\t Mixed_7c.branch3x3dbl_3a.conv.weight\n",
      "\t Mixed_7c.branch3x3dbl_3a.bn.weight\n",
      "\t Mixed_7c.branch3x3dbl_3a.bn.bias\n",
      "\t Mixed_7c.branch3x3dbl_3b.conv.weight\n",
      "\t Mixed_7c.branch3x3dbl_3b.bn.weight\n",
      "\t Mixed_7c.branch3x3dbl_3b.bn.bias\n",
      "\t Mixed_7c.branch_pool.conv.weight\n",
      "\t Mixed_7c.branch_pool.bn.weight\n",
      "\t Mixed_7c.branch_pool.bn.bias\n",
      "\t fc.weight\n",
      "\t fc.bias\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-0c9d3efd2e91>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmake_inception_v3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mselected_birds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_extract\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcross_validate_net\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet_generator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrepeat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_inception\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[0mprint_validation_results\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-fac5e13d4d79>\u001b[0m in \u001b[0;36mcross_validate_net\u001b[1;34m(net_generator, dataset, repeat, epochs, batch_size, is_inception)\u001b[0m\n\u001b[0;32m     36\u001b[0m         \u001b[0mnet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnet_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m         \u001b[0mearly_stopping\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnet_training\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEarlyStoppingByAccuracy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpatience\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m         results = train_net_random_dataset_split(net, dataset, epochs,optimizer=optimizer,\n\u001b[0m\u001b[0;32m     39\u001b[0m                                                  early_stopping=early_stopping, batch_size=batch_size, is_inception=is_inception)\n\u001b[0;32m     40\u001b[0m         \u001b[0mall_results\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-fac5e13d4d79>\u001b[0m in \u001b[0;36mtrain_net_random_dataset_split\u001b[1;34m(net, dataset, epochs, optimizer, batch_size, early_stopping, is_inception)\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[0mdevice\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;31m# Wybiera CUDA jeśli jest dostępne, w przeciwnym wypadku CPU\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[1;31m# device = \"cpu\" # Odkomentować jeżeli CUDA nie będzie działać\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m     results = net_training.train_and_evaluate(net, train_dataloader, test_dataloader, label_set,early_stopping = early_stopping,\n\u001b[0m\u001b[0;32m     26\u001b[0m                                  epochs=epochs, optimizer=optimizer, print_results=True, device=device, is_inception=is_inception)\n\u001b[0;32m     27\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\Studia\\BIAI\\birds\\experiment\\net_training.py\u001b[0m in \u001b[0;36mtrain_and_evaluate\u001b[1;34m(net, train_dataloader, test_dataloader, label_set, epochs, optimizer, early_stopping, print_results, is_inception, device)\u001b[0m\n\u001b[0;32m    149\u001b[0m         \u001b[0mstart_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    150\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_inception\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 151\u001b[1;33m             \u001b[0mtrain_results\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_inception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    152\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    153\u001b[0m             \u001b[0mtrain_results\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\Studia\\BIAI\\birds\\experiment\\net_training.py\u001b[0m in \u001b[0;36mtrain_inception\u001b[1;34m(net, train_dataloader, criterion, optimizer, device)\u001b[0m\n\u001b[0;32m     71\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss1\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m0.4\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mloss2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m         \u001b[0mrunning_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m     \u001b[0mepoch_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrunning_loss\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\dominik\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    243\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    244\u001b[0m                 inputs=inputs)\n\u001b[1;32m--> 245\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    246\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    247\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\dominik\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    143\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    144\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 145\u001b[1;33m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[0;32m    146\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    147\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dataset_dir = \"../data/birds270\"\n",
    "selected_birds = [\"ALBATROSS\", \"BALD EAGLE\", \"BARN OWL\", \"EURASIAN MAGPIE\", \"FLAMINGO\",\n",
    "                  \"MALLARD DUCK\", \"OSTRICH\", \"PEACOCK\", \"PELICAN\", \"TRUMPTER SWAN\"]\n",
    "\n",
    "#transform = transforms.Normalize((127.5, 127.5, 127.5), (127.5, 127.5, 127.5)) # normalizes colors to range [-1,1]\n",
    "transform =  transforms.Compose([\n",
    "    transforms.Normalize((0, 0, 0), (255, 255, 255)),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "transform_inception =  transforms.Compose([\n",
    "    transforms.Resize([299, 299]),\n",
    "    transforms.Normalize((0, 0, 0), (255, 255, 255)),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "#dataset = Birds270Dataset(dataset_dir,  selected_birds=selected_birds, transform=transform)\n",
    "dataset = Birds270Dataset(dataset_dir,  selected_birds=selected_birds, transform=transform_inception)\n",
    "\n",
    "def net_generator():\n",
    "    return make_inception_v3(out_features=len(selected_birds), feature_extract = False)\n",
    "\n",
    "results = cross_validate_net(net_generator, dataset, repeat=5, epochs=100, batch_size=64, is_inception=True)\n",
    "print_validation_results(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a338172",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = results_to_dataframe(results)\n",
    "dataframe.to_csv(\"../results/inception_v3_pretrained.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1547d404",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
