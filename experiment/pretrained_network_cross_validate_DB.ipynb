{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "626897ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_parameter_requires_grad(model, feature_extracting):\n",
    "    if feature_extracting:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "def get_params_to_update(net, feature_extract):\n",
    "    params_to_update = net.parameters()\n",
    "    print(\"Params to learn:\")\n",
    "    if feature_extract:\n",
    "        params_to_update = []\n",
    "        for name,param in net.named_parameters():\n",
    "            if param.requires_grad == True:\n",
    "                params_to_update.append(param)\n",
    "                print(\"\\t\",name)\n",
    "    else:\n",
    "        for name,param in net.named_parameters():\n",
    "            if param.requires_grad == True:\n",
    "                print(\"\\t\",name)\n",
    "    return params_to_update\n",
    "\n",
    "def make_alexnet(out_features, feature_extract = False):\n",
    "    net = models.alexnet(pretrained=True)\n",
    "    set_parameter_requires_grad(net, feature_extract)\n",
    "    num_ftrs = net.classifier[6].in_features\n",
    "    net.classifier[6] = nn.Linear(num_ftrs, out_features)\n",
    "    params_to_update = get_params_to_update(net, feature_extract)\n",
    "    optimizer = optim.Adam(params_to_update, lr=0.0001)\n",
    "    return net, optimizer\n",
    "\n",
    "def make_mobilenet_v3(out_features, feature_extract = False):\n",
    "    net = models.mobilenet_v3_small(pretrained=True)\n",
    "    set_parameter_requires_grad(net, feature_extract)\n",
    "    num_ftrs = net.classifier[3].in_features\n",
    "    net.classifier[3] = nn.Linear(num_ftrs, out_features)\n",
    "    params_to_update = get_params_to_update(net, feature_extract)\n",
    "    optimizer = optim.Adam(params_to_update, lr=0.0001)\n",
    "    return net, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2e73ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics\n",
    "import torch.utils.data as td\n",
    "import net_training\n",
    "from birds_dataset import Birds270Dataset\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets, models\n",
    "import pandas as pd\n",
    "\n",
    "# Splits a dataset randomly into a train and test set. The size of test set is 80% of the whole dataset.\n",
    "# Then it trains the network\n",
    "def train_net_random_dataset_split(net, dataset, epochs, optimizer, batch_size, early_stopping):\n",
    "    train_set_size = int(len(dataset)*0.8)\n",
    "    test_set_size = len(dataset)-train_set_size\n",
    "    train_dataset, test_dataset = td.random_split(dataset, [train_set_size, test_set_size])\n",
    "    label_set = dataset.get_label_set()\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size, shuffle=True)\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size, shuffle=True)\n",
    "    results = net_training.train_and_evaluate(net, train_dataloader, test_dataloader, label_set,early_stopping = early_stopping,\n",
    "                                 epochs=epochs, optimizer=optimizer, print_results=True)\n",
    "    return results\n",
    "\n",
    "# Creates a few networks and trains them using a random split of the dataset.\n",
    "# The number of created networks is in the \"repeat\" argument\n",
    "# It returns the final validation results for each network\n",
    "def cross_validate_net(net_generator, dataset, repeat=5, epochs=20, batch_size=32):\n",
    "    all_results = []\n",
    "    for i in range(repeat):\n",
    "        print(f\"Training network {i+1} ...\")\n",
    "        net, optimizer = net_generator()\n",
    "        early_stopping = net_training.EarlyStoppingByAccuracy(patience=10)\n",
    "        results = train_net_random_dataset_split(net, dataset, epochs,optimizer=optimizer,\n",
    "                                                 early_stopping=early_stopping, batch_size=batch_size)\n",
    "        all_results.append(results)\n",
    "        net_training.print_final_results(results)\n",
    "    return all_results\n",
    "    \n",
    "    \n",
    "def print_validation_results(cross_validation_results):\n",
    "    losses = [r[\"loss\"] for r in cross_validation_results]\n",
    "    accuracies = [r[\"accuracy\"] for r in cross_validation_results]\n",
    "    print(\"Losses: \", losses)\n",
    "    print(\"Loss:  mean: {:.4f}, std: {:.4f}\".format(statistics.mean(losses), statistics.stdev(losses)))\n",
    "    print(\"Accuracies: \", accuracies)\n",
    "    print(\"Accuracy:  mean: {:.4f}, std: {:.4f}\".format(statistics.mean(accuracies), statistics.stdev(accuracies)))\n",
    "    \n",
    "def results_to_dataframe(cross_validation_results):\n",
    "    normalized = pd.json_normalize(cross_validation_results)\n",
    "    return normalized\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44012fb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training network 1 ...\n",
      "Params to learn:\n",
      "\t features.0.0.weight\n",
      "\t features.0.1.weight\n",
      "\t features.0.1.bias\n",
      "\t features.1.block.0.0.weight\n",
      "\t features.1.block.0.1.weight\n",
      "\t features.1.block.0.1.bias\n",
      "\t features.1.block.1.fc1.weight\n",
      "\t features.1.block.1.fc1.bias\n",
      "\t features.1.block.1.fc2.weight\n",
      "\t features.1.block.1.fc2.bias\n",
      "\t features.1.block.2.0.weight\n",
      "\t features.1.block.2.1.weight\n",
      "\t features.1.block.2.1.bias\n",
      "\t features.2.block.0.0.weight\n",
      "\t features.2.block.0.1.weight\n",
      "\t features.2.block.0.1.bias\n",
      "\t features.2.block.1.0.weight\n",
      "\t features.2.block.1.1.weight\n",
      "\t features.2.block.1.1.bias\n",
      "\t features.2.block.2.0.weight\n",
      "\t features.2.block.2.1.weight\n",
      "\t features.2.block.2.1.bias\n",
      "\t features.3.block.0.0.weight\n",
      "\t features.3.block.0.1.weight\n",
      "\t features.3.block.0.1.bias\n",
      "\t features.3.block.1.0.weight\n",
      "\t features.3.block.1.1.weight\n",
      "\t features.3.block.1.1.bias\n",
      "\t features.3.block.2.0.weight\n",
      "\t features.3.block.2.1.weight\n",
      "\t features.3.block.2.1.bias\n",
      "\t features.4.block.0.0.weight\n",
      "\t features.4.block.0.1.weight\n",
      "\t features.4.block.0.1.bias\n",
      "\t features.4.block.1.0.weight\n",
      "\t features.4.block.1.1.weight\n",
      "\t features.4.block.1.1.bias\n",
      "\t features.4.block.2.fc1.weight\n",
      "\t features.4.block.2.fc1.bias\n",
      "\t features.4.block.2.fc2.weight\n",
      "\t features.4.block.2.fc2.bias\n",
      "\t features.4.block.3.0.weight\n",
      "\t features.4.block.3.1.weight\n",
      "\t features.4.block.3.1.bias\n",
      "\t features.5.block.0.0.weight\n",
      "\t features.5.block.0.1.weight\n",
      "\t features.5.block.0.1.bias\n",
      "\t features.5.block.1.0.weight\n",
      "\t features.5.block.1.1.weight\n",
      "\t features.5.block.1.1.bias\n",
      "\t features.5.block.2.fc1.weight\n",
      "\t features.5.block.2.fc1.bias\n",
      "\t features.5.block.2.fc2.weight\n",
      "\t features.5.block.2.fc2.bias\n",
      "\t features.5.block.3.0.weight\n",
      "\t features.5.block.3.1.weight\n",
      "\t features.5.block.3.1.bias\n",
      "\t features.6.block.0.0.weight\n",
      "\t features.6.block.0.1.weight\n",
      "\t features.6.block.0.1.bias\n",
      "\t features.6.block.1.0.weight\n",
      "\t features.6.block.1.1.weight\n",
      "\t features.6.block.1.1.bias\n",
      "\t features.6.block.2.fc1.weight\n",
      "\t features.6.block.2.fc1.bias\n",
      "\t features.6.block.2.fc2.weight\n",
      "\t features.6.block.2.fc2.bias\n",
      "\t features.6.block.3.0.weight\n",
      "\t features.6.block.3.1.weight\n",
      "\t features.6.block.3.1.bias\n",
      "\t features.7.block.0.0.weight\n",
      "\t features.7.block.0.1.weight\n",
      "\t features.7.block.0.1.bias\n",
      "\t features.7.block.1.0.weight\n",
      "\t features.7.block.1.1.weight\n",
      "\t features.7.block.1.1.bias\n",
      "\t features.7.block.2.fc1.weight\n",
      "\t features.7.block.2.fc1.bias\n",
      "\t features.7.block.2.fc2.weight\n",
      "\t features.7.block.2.fc2.bias\n",
      "\t features.7.block.3.0.weight\n",
      "\t features.7.block.3.1.weight\n",
      "\t features.7.block.3.1.bias\n",
      "\t features.8.block.0.0.weight\n",
      "\t features.8.block.0.1.weight\n",
      "\t features.8.block.0.1.bias\n",
      "\t features.8.block.1.0.weight\n",
      "\t features.8.block.1.1.weight\n",
      "\t features.8.block.1.1.bias\n",
      "\t features.8.block.2.fc1.weight\n",
      "\t features.8.block.2.fc1.bias\n",
      "\t features.8.block.2.fc2.weight\n",
      "\t features.8.block.2.fc2.bias\n",
      "\t features.8.block.3.0.weight\n",
      "\t features.8.block.3.1.weight\n",
      "\t features.8.block.3.1.bias\n",
      "\t features.9.block.0.0.weight\n",
      "\t features.9.block.0.1.weight\n",
      "\t features.9.block.0.1.bias\n",
      "\t features.9.block.1.0.weight\n",
      "\t features.9.block.1.1.weight\n",
      "\t features.9.block.1.1.bias\n",
      "\t features.9.block.2.fc1.weight\n",
      "\t features.9.block.2.fc1.bias\n",
      "\t features.9.block.2.fc2.weight\n",
      "\t features.9.block.2.fc2.bias\n",
      "\t features.9.block.3.0.weight\n",
      "\t features.9.block.3.1.weight\n",
      "\t features.9.block.3.1.bias\n",
      "\t features.10.block.0.0.weight\n",
      "\t features.10.block.0.1.weight\n",
      "\t features.10.block.0.1.bias\n",
      "\t features.10.block.1.0.weight\n",
      "\t features.10.block.1.1.weight\n",
      "\t features.10.block.1.1.bias\n",
      "\t features.10.block.2.fc1.weight\n",
      "\t features.10.block.2.fc1.bias\n",
      "\t features.10.block.2.fc2.weight\n",
      "\t features.10.block.2.fc2.bias\n",
      "\t features.10.block.3.0.weight\n",
      "\t features.10.block.3.1.weight\n",
      "\t features.10.block.3.1.bias\n",
      "\t features.11.block.0.0.weight\n",
      "\t features.11.block.0.1.weight\n",
      "\t features.11.block.0.1.bias\n",
      "\t features.11.block.1.0.weight\n",
      "\t features.11.block.1.1.weight\n",
      "\t features.11.block.1.1.bias\n",
      "\t features.11.block.2.fc1.weight\n",
      "\t features.11.block.2.fc1.bias\n",
      "\t features.11.block.2.fc2.weight\n",
      "\t features.11.block.2.fc2.bias\n",
      "\t features.11.block.3.0.weight\n",
      "\t features.11.block.3.1.weight\n",
      "\t features.11.block.3.1.bias\n",
      "\t features.12.0.weight\n",
      "\t features.12.1.weight\n",
      "\t features.12.1.bias\n",
      "\t classifier.0.weight\n",
      "\t classifier.0.bias\n",
      "\t classifier.3.weight\n",
      "\t classifier.3.bias\n",
      "Epoch 0:\n",
      "\ttrain loss: 1.9405217475384013\n",
      "\tvalidation loss: 1.3070771988124064, validation accuracy: 74.65753424657534%\n",
      "\tElapsed time: 0:03:59.279995\n",
      "Epoch 1:\n",
      "\ttrain loss: 1.1642305156787918\n",
      "\tvalidation loss: 0.7104343167723042, validation accuracy: 89.04109589041096%\n",
      "\tElapsed time: 0:03:54.407240\n",
      "Epoch 2:\n",
      "\ttrain loss: 0.6589428361243286\n",
      "\tvalidation loss: 0.4151257284700054, validation accuracy: 93.4931506849315%\n",
      "\tElapsed time: 0:03:47.808303\n",
      "Epoch 3:\n",
      "\ttrain loss: 0.3613683846659358\n",
      "\tvalidation loss: 0.2705191908633872, validation accuracy: 95.2054794520548%\n",
      "\tElapsed time: 0:03:44.375954\n",
      "Epoch 4:\n",
      "\ttrain loss: 0.20857481200944497\n",
      "\tvalidation loss: 0.2001247598904453, validation accuracy: 95.8904109589041%\n",
      "\tElapsed time: 0:03:44.495259\n",
      "Epoch 5:\n",
      "\ttrain loss: 0.12255774301638121\n",
      "\tvalidation loss: 0.15677228774109933, validation accuracy: 96.91780821917808%\n",
      "\tElapsed time: 0:03:42.862651\n",
      "Epoch 6:\n",
      "\ttrain loss: 0.079666634289928\n",
      "\tvalidation loss: 0.1362894480052876, validation accuracy: 96.91780821917808%\n",
      "\tElapsed time: 0:03:41.257321\n",
      "Epoch 7:\n",
      "\ttrain loss: 0.053277956708422246\n",
      "\tvalidation loss: 0.1253611055547244, validation accuracy: 97.26027397260275%\n",
      "\tElapsed time: 0:03:45.136306\n",
      "Epoch 8:\n",
      "\ttrain loss: 0.037661972179318784\n",
      "\tvalidation loss: 0.11436051967209332, validation accuracy: 96.91780821917808%\n",
      "\tElapsed time: 0:03:58.283878\n",
      "Epoch 9:\n",
      "\ttrain loss: 0.028705182272819468\n",
      "\tvalidation loss: 0.10635318321316209, validation accuracy: 97.26027397260275%\n",
      "\tElapsed time: 0:03:56.290280\n",
      "Epoch 10:\n",
      "\ttrain loss: 0.019304499017333495\n",
      "\tvalidation loss: 0.09865679010136487, validation accuracy: 97.26027397260275%\n",
      "\tElapsed time: 0:04:03.500241\n",
      "Epoch 11:\n",
      "\ttrain loss: 0.01614055666261022\n",
      "\tvalidation loss: 0.09320209624424372, validation accuracy: 97.26027397260275%\n",
      "\tElapsed time: 0:03:55.948203\n",
      "Epoch 12:\n",
      "\ttrain loss: 0.014833652441538423\n",
      "\tvalidation loss: 0.09140013331828052, validation accuracy: 96.57534246575342%\n",
      "\tElapsed time: 0:04:02.719090\n",
      "Epoch 13:\n",
      "\ttrain loss: 0.010804689740107154\n",
      "\tvalidation loss: 0.09904432980573341, validation accuracy: 96.91780821917808%\n",
      "\tElapsed time: 0:03:48.697733\n",
      "Epoch 14:\n",
      "\ttrain loss: 0.009617379225956638\n",
      "\tvalidation loss: 0.09180116291119628, validation accuracy: 96.91780821917808%\n",
      "\tElapsed time: 0:03:48.075164\n",
      "Epoch 15:\n",
      "\ttrain loss: 0.00804118153608786\n",
      "\tvalidation loss: 0.08670764179160334, validation accuracy: 97.26027397260275%\n",
      "\tElapsed time: 0:03:50.195294\n",
      "Epoch 16:\n",
      "\ttrain loss: 0.006768065043062125\n",
      "\tvalidation loss: 0.08452587753330192, validation accuracy: 97.26027397260275%\n",
      "\tElapsed time: 0:04:00.670844\n",
      "Epoch 17:\n",
      "\ttrain loss: 0.005998882703086933\n",
      "\tvalidation loss: 0.08435911940385217, validation accuracy: 97.26027397260275%\n",
      "\tElapsed time: 0:03:59.850074\n",
      "Final loss: 0.0844, final accuracy: 97.26 %\n",
      "\tALBATROSS: 100.00%\n",
      "\tBALD EAGLE: 93.33%\n",
      "\tBARN OWL: 100.00%\n",
      "\tEURASIAN MAGPIE: 100.00%\n",
      "\tFLAMINGO: 96.88%\n",
      "\tMALLARD DUCK: 97.30%\n",
      "\tOSTRICH: 96.43%\n",
      "\tPEACOCK: 100.00%\n",
      "\tPELICAN: 90.32%\n",
      "\tTRUMPTER SWAN: 100.00%\n",
      "Final loss: 0.0844, final accuracy: 97.26 %\n",
      "\tALBATROSS: 100.00%\n",
      "\tBALD EAGLE: 93.33%\n",
      "\tBARN OWL: 100.00%\n",
      "\tEURASIAN MAGPIE: 100.00%\n",
      "\tFLAMINGO: 96.88%\n",
      "\tMALLARD DUCK: 97.30%\n",
      "\tOSTRICH: 96.43%\n",
      "\tPEACOCK: 100.00%\n",
      "\tPELICAN: 90.32%\n",
      "\tTRUMPTER SWAN: 100.00%\n",
      "Training network 2 ...\n",
      "Params to learn:\n",
      "\t features.0.0.weight\n",
      "\t features.0.1.weight\n",
      "\t features.0.1.bias\n",
      "\t features.1.block.0.0.weight\n",
      "\t features.1.block.0.1.weight\n",
      "\t features.1.block.0.1.bias\n",
      "\t features.1.block.1.fc1.weight\n",
      "\t features.1.block.1.fc1.bias\n",
      "\t features.1.block.1.fc2.weight\n",
      "\t features.1.block.1.fc2.bias\n",
      "\t features.1.block.2.0.weight\n",
      "\t features.1.block.2.1.weight\n",
      "\t features.1.block.2.1.bias\n",
      "\t features.2.block.0.0.weight\n",
      "\t features.2.block.0.1.weight\n",
      "\t features.2.block.0.1.bias\n",
      "\t features.2.block.1.0.weight\n",
      "\t features.2.block.1.1.weight\n",
      "\t features.2.block.1.1.bias\n",
      "\t features.2.block.2.0.weight\n",
      "\t features.2.block.2.1.weight\n",
      "\t features.2.block.2.1.bias\n",
      "\t features.3.block.0.0.weight\n",
      "\t features.3.block.0.1.weight\n",
      "\t features.3.block.0.1.bias\n",
      "\t features.3.block.1.0.weight\n",
      "\t features.3.block.1.1.weight\n",
      "\t features.3.block.1.1.bias\n",
      "\t features.3.block.2.0.weight\n",
      "\t features.3.block.2.1.weight\n",
      "\t features.3.block.2.1.bias\n",
      "\t features.4.block.0.0.weight\n",
      "\t features.4.block.0.1.weight\n",
      "\t features.4.block.0.1.bias\n",
      "\t features.4.block.1.0.weight\n",
      "\t features.4.block.1.1.weight\n",
      "\t features.4.block.1.1.bias\n",
      "\t features.4.block.2.fc1.weight\n",
      "\t features.4.block.2.fc1.bias\n",
      "\t features.4.block.2.fc2.weight\n",
      "\t features.4.block.2.fc2.bias\n",
      "\t features.4.block.3.0.weight\n",
      "\t features.4.block.3.1.weight\n",
      "\t features.4.block.3.1.bias\n",
      "\t features.5.block.0.0.weight\n",
      "\t features.5.block.0.1.weight\n",
      "\t features.5.block.0.1.bias\n",
      "\t features.5.block.1.0.weight\n",
      "\t features.5.block.1.1.weight\n",
      "\t features.5.block.1.1.bias\n",
      "\t features.5.block.2.fc1.weight\n",
      "\t features.5.block.2.fc1.bias\n",
      "\t features.5.block.2.fc2.weight\n",
      "\t features.5.block.2.fc2.bias\n",
      "\t features.5.block.3.0.weight\n",
      "\t features.5.block.3.1.weight\n",
      "\t features.5.block.3.1.bias\n",
      "\t features.6.block.0.0.weight\n",
      "\t features.6.block.0.1.weight\n",
      "\t features.6.block.0.1.bias\n",
      "\t features.6.block.1.0.weight\n",
      "\t features.6.block.1.1.weight\n",
      "\t features.6.block.1.1.bias\n",
      "\t features.6.block.2.fc1.weight\n",
      "\t features.6.block.2.fc1.bias\n",
      "\t features.6.block.2.fc2.weight\n",
      "\t features.6.block.2.fc2.bias\n",
      "\t features.6.block.3.0.weight\n",
      "\t features.6.block.3.1.weight\n",
      "\t features.6.block.3.1.bias\n",
      "\t features.7.block.0.0.weight\n",
      "\t features.7.block.0.1.weight\n",
      "\t features.7.block.0.1.bias\n",
      "\t features.7.block.1.0.weight\n",
      "\t features.7.block.1.1.weight\n",
      "\t features.7.block.1.1.bias\n",
      "\t features.7.block.2.fc1.weight\n",
      "\t features.7.block.2.fc1.bias\n",
      "\t features.7.block.2.fc2.weight\n",
      "\t features.7.block.2.fc2.bias\n",
      "\t features.7.block.3.0.weight\n",
      "\t features.7.block.3.1.weight\n",
      "\t features.7.block.3.1.bias\n",
      "\t features.8.block.0.0.weight\n",
      "\t features.8.block.0.1.weight\n",
      "\t features.8.block.0.1.bias\n",
      "\t features.8.block.1.0.weight\n",
      "\t features.8.block.1.1.weight\n",
      "\t features.8.block.1.1.bias\n",
      "\t features.8.block.2.fc1.weight\n",
      "\t features.8.block.2.fc1.bias\n",
      "\t features.8.block.2.fc2.weight\n",
      "\t features.8.block.2.fc2.bias\n",
      "\t features.8.block.3.0.weight\n",
      "\t features.8.block.3.1.weight\n",
      "\t features.8.block.3.1.bias\n",
      "\t features.9.block.0.0.weight\n",
      "\t features.9.block.0.1.weight\n",
      "\t features.9.block.0.1.bias\n",
      "\t features.9.block.1.0.weight\n",
      "\t features.9.block.1.1.weight\n",
      "\t features.9.block.1.1.bias\n",
      "\t features.9.block.2.fc1.weight\n",
      "\t features.9.block.2.fc1.bias\n",
      "\t features.9.block.2.fc2.weight\n",
      "\t features.9.block.2.fc2.bias\n",
      "\t features.9.block.3.0.weight\n",
      "\t features.9.block.3.1.weight\n",
      "\t features.9.block.3.1.bias\n",
      "\t features.10.block.0.0.weight\n",
      "\t features.10.block.0.1.weight\n",
      "\t features.10.block.0.1.bias\n",
      "\t features.10.block.1.0.weight\n",
      "\t features.10.block.1.1.weight\n",
      "\t features.10.block.1.1.bias\n",
      "\t features.10.block.2.fc1.weight\n",
      "\t features.10.block.2.fc1.bias\n",
      "\t features.10.block.2.fc2.weight\n",
      "\t features.10.block.2.fc2.bias\n",
      "\t features.10.block.3.0.weight\n",
      "\t features.10.block.3.1.weight\n",
      "\t features.10.block.3.1.bias\n",
      "\t features.11.block.0.0.weight\n",
      "\t features.11.block.0.1.weight\n",
      "\t features.11.block.0.1.bias\n",
      "\t features.11.block.1.0.weight\n",
      "\t features.11.block.1.1.weight\n",
      "\t features.11.block.1.1.bias\n",
      "\t features.11.block.2.fc1.weight\n",
      "\t features.11.block.2.fc1.bias\n",
      "\t features.11.block.2.fc2.weight\n",
      "\t features.11.block.2.fc2.bias\n",
      "\t features.11.block.3.0.weight\n",
      "\t features.11.block.3.1.weight\n",
      "\t features.11.block.3.1.bias\n",
      "\t features.12.0.weight\n",
      "\t features.12.1.weight\n",
      "\t features.12.1.bias\n",
      "\t classifier.0.weight\n",
      "\t classifier.0.bias\n",
      "\t classifier.3.weight\n",
      "\t classifier.3.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:\n",
      "\ttrain loss: 1.946858163558803\n",
      "\tvalidation loss: 1.3366217727530492, validation accuracy: 76.36986301369863%\n",
      "\tElapsed time: 0:03:54.749025\n",
      "Epoch 1:\n",
      "\ttrain loss: 1.1622855219587453\n",
      "\tvalidation loss: 0.6951420862380773, validation accuracy: 90.06849315068493%\n",
      "\tElapsed time: 0:03:57.343509\n",
      "Epoch 2:\n",
      "\ttrain loss: 0.6610197734157994\n",
      "\tvalidation loss: 0.3807565120801534, validation accuracy: 92.8082191780822%\n",
      "\tElapsed time: 0:03:52.294955\n",
      "Epoch 3:\n",
      "\ttrain loss: 0.36555646592511526\n",
      "\tvalidation loss: 0.24067089206551853, validation accuracy: 95.54794520547945%\n",
      "\tElapsed time: 0:03:51.422621\n",
      "Epoch 4:\n",
      "\ttrain loss: 0.217464461155862\n",
      "\tvalidation loss: 0.17175892424093533, validation accuracy: 97.26027397260275%\n",
      "\tElapsed time: 0:03:48.577829\n",
      "Epoch 5:\n",
      "\ttrain loss: 0.1320129438186796\n",
      "\tvalidation loss: 0.13017521961911083, validation accuracy: 97.26027397260275%\n",
      "\tElapsed time: 0:03:47.559030\n",
      "Epoch 6:\n",
      "\ttrain loss: 0.08062052910773668\n",
      "\tvalidation loss: 0.10550113124390172, validation accuracy: 97.94520547945206%\n",
      "\tElapsed time: 0:03:46.087769\n",
      "Epoch 7:\n",
      "\ttrain loss: 0.05825817526204713\n",
      "\tvalidation loss: 0.08866840600967407, validation accuracy: 98.63013698630137%\n",
      "\tElapsed time: 0:03:45.998570\n",
      "Epoch 8:\n",
      "\ttrain loss: 0.04405075831156652\n",
      "\tvalidation loss: 0.08061278999260027, validation accuracy: 98.28767123287672%\n",
      "\tElapsed time: 0:03:44.807059\n",
      "Epoch 9:\n",
      "\ttrain loss: 0.03118910372103876\n",
      "\tvalidation loss: 0.07171753947048971, validation accuracy: 98.63013698630137%\n",
      "\tElapsed time: 0:03:43.263087\n",
      "Epoch 10:\n",
      "\ttrain loss: 0.022245114372075114\n",
      "\tvalidation loss: 0.06802577535583548, validation accuracy: 98.63013698630137%\n",
      "\tElapsed time: 0:03:52.106862\n",
      "Epoch 11:\n",
      "\ttrain loss: 0.023037746983163354\n",
      "\tvalidation loss: 0.05972700127183574, validation accuracy: 98.63013698630137%\n",
      "\tElapsed time: 0:03:46.144719\n",
      "Epoch 12:\n",
      "\ttrain loss: 0.01600238013418318\n",
      "\tvalidation loss: 0.056405457068387774, validation accuracy: 98.63013698630137%\n",
      "\tElapsed time: 0:03:45.997983\n",
      "Epoch 13:\n",
      "\ttrain loss: 0.01250994344134887\n",
      "\tvalidation loss: 0.052076187035808824, validation accuracy: 98.97260273972603%\n",
      "\tElapsed time: 0:03:45.137452\n",
      "Epoch 14:\n",
      "\ttrain loss: 0.010299795136290186\n",
      "\tvalidation loss: 0.047782121506864075, validation accuracy: 98.63013698630137%\n",
      "\tElapsed time: 0:03:42.727400\n",
      "Epoch 15:\n",
      "\ttrain loss: 0.0077475763531481626\n",
      "\tvalidation loss: 0.04561727948180617, validation accuracy: 98.97260273972603%\n",
      "\tElapsed time: 0:03:42.561411\n",
      "Epoch 16:\n",
      "\ttrain loss: 0.009091709237258185\n",
      "\tvalidation loss: 0.044091624858444686, validation accuracy: 98.97260273972603%\n",
      "\tElapsed time: 0:03:48.944807\n",
      "Epoch 17:\n",
      "\ttrain loss: 0.008428606854857138\n",
      "\tvalidation loss: 0.045987097623005305, validation accuracy: 98.97260273972603%\n",
      "\tElapsed time: 0:04:01.680291\n",
      "Epoch 18:\n",
      "\ttrain loss: 0.007956452629373986\n",
      "\tvalidation loss: 0.05151970914169533, validation accuracy: 99.31506849315068%\n",
      "\tElapsed time: 0:04:13.846814\n",
      "Epoch 19:\n",
      "\ttrain loss: 0.006941261399364799\n",
      "\tvalidation loss: 0.05201954971233459, validation accuracy: 98.63013698630137%\n",
      "\tElapsed time: 0:04:16.055478\n",
      "Epoch 20:\n",
      "\ttrain loss: 0.006031879830920165\n",
      "\tvalidation loss: 0.04488454256461908, validation accuracy: 98.97260273972603%\n",
      "\tElapsed time: 0:04:10.933652\n",
      "Epoch 21:\n",
      "\ttrain loss: 0.00454843273677098\n",
      "\tvalidation loss: 0.0435848058494803, validation accuracy: 98.97260273972603%\n",
      "\tElapsed time: 0:04:14.439902\n",
      "Epoch 22:\n",
      "\ttrain loss: 0.0071893190744606135\n",
      "\tvalidation loss: 0.04274269040316751, validation accuracy: 98.63013698630137%\n",
      "\tElapsed time: 0:04:13.572414\n",
      "Epoch 23:\n",
      "\ttrain loss: 0.00520365714298411\n",
      "\tvalidation loss: 0.04176767642469439, validation accuracy: 98.97260273972603%\n",
      "\tElapsed time: 0:04:14.470989\n",
      "Epoch 24:\n",
      "\ttrain loss: 0.0042884859574342064\n",
      "\tvalidation loss: 0.03854196028758402, validation accuracy: 98.97260273972603%\n",
      "\tElapsed time: 0:04:45.266474\n",
      "Epoch 25:\n",
      "\ttrain loss: 0.003300742931523413\n",
      "\tvalidation loss: 0.036120247657168404, validation accuracy: 98.97260273972603%\n",
      "\tElapsed time: 0:04:26.275897\n",
      "Epoch 26:\n",
      "\ttrain loss: 0.0030734353570194073\n",
      "\tvalidation loss: 0.03494828191828238, validation accuracy: 98.97260273972603%\n",
      "\tElapsed time: 0:04:47.887825\n",
      "Epoch 27:\n",
      "\ttrain loss: 0.0022290160266065884\n",
      "\tvalidation loss: 0.03437546721008951, validation accuracy: 98.97260273972603%\n",
      "\tElapsed time: 0:04:48.984410\n",
      "Epoch 28:\n",
      "\ttrain loss: 0.002521970419542254\n",
      "\tvalidation loss: 0.03411744644686784, validation accuracy: 98.97260273972603%\n",
      "\tElapsed time: 0:06:45.151265\n",
      "Final loss: 0.0341, final accuracy: 98.97 %\n",
      "\tALBATROSS: 94.44%\n",
      "\tBALD EAGLE: 100.00%\n",
      "\tBARN OWL: 100.00%\n",
      "\tEURASIAN MAGPIE: 96.55%\n",
      "\tFLAMINGO: 100.00%\n",
      "\tMALLARD DUCK: 96.00%\n",
      "\tOSTRICH: 100.00%\n",
      "\tPEACOCK: 100.00%\n",
      "\tPELICAN: 100.00%\n",
      "\tTRUMPTER SWAN: 100.00%\n",
      "Final loss: 0.0341, final accuracy: 98.97 %\n",
      "\tALBATROSS: 94.44%\n",
      "\tBALD EAGLE: 100.00%\n",
      "\tBARN OWL: 100.00%\n",
      "\tEURASIAN MAGPIE: 96.55%\n",
      "\tFLAMINGO: 100.00%\n",
      "\tMALLARD DUCK: 96.00%\n",
      "\tOSTRICH: 100.00%\n",
      "\tPEACOCK: 100.00%\n",
      "\tPELICAN: 100.00%\n",
      "\tTRUMPTER SWAN: 100.00%\n",
      "Training network 3 ...\n",
      "Params to learn:\n",
      "\t features.0.0.weight\n",
      "\t features.0.1.weight\n",
      "\t features.0.1.bias\n",
      "\t features.1.block.0.0.weight\n",
      "\t features.1.block.0.1.weight\n",
      "\t features.1.block.0.1.bias\n",
      "\t features.1.block.1.fc1.weight\n",
      "\t features.1.block.1.fc1.bias\n",
      "\t features.1.block.1.fc2.weight\n",
      "\t features.1.block.1.fc2.bias\n",
      "\t features.1.block.2.0.weight\n",
      "\t features.1.block.2.1.weight\n",
      "\t features.1.block.2.1.bias\n",
      "\t features.2.block.0.0.weight\n",
      "\t features.2.block.0.1.weight\n",
      "\t features.2.block.0.1.bias\n",
      "\t features.2.block.1.0.weight\n",
      "\t features.2.block.1.1.weight\n",
      "\t features.2.block.1.1.bias\n",
      "\t features.2.block.2.0.weight\n",
      "\t features.2.block.2.1.weight\n",
      "\t features.2.block.2.1.bias\n",
      "\t features.3.block.0.0.weight\n",
      "\t features.3.block.0.1.weight\n",
      "\t features.3.block.0.1.bias\n",
      "\t features.3.block.1.0.weight\n",
      "\t features.3.block.1.1.weight\n",
      "\t features.3.block.1.1.bias\n",
      "\t features.3.block.2.0.weight\n",
      "\t features.3.block.2.1.weight\n",
      "\t features.3.block.2.1.bias\n",
      "\t features.4.block.0.0.weight\n",
      "\t features.4.block.0.1.weight\n",
      "\t features.4.block.0.1.bias\n",
      "\t features.4.block.1.0.weight\n",
      "\t features.4.block.1.1.weight\n",
      "\t features.4.block.1.1.bias\n",
      "\t features.4.block.2.fc1.weight\n",
      "\t features.4.block.2.fc1.bias\n",
      "\t features.4.block.2.fc2.weight\n",
      "\t features.4.block.2.fc2.bias\n",
      "\t features.4.block.3.0.weight\n",
      "\t features.4.block.3.1.weight\n",
      "\t features.4.block.3.1.bias\n",
      "\t features.5.block.0.0.weight\n",
      "\t features.5.block.0.1.weight\n",
      "\t features.5.block.0.1.bias\n",
      "\t features.5.block.1.0.weight\n",
      "\t features.5.block.1.1.weight\n",
      "\t features.5.block.1.1.bias\n",
      "\t features.5.block.2.fc1.weight\n",
      "\t features.5.block.2.fc1.bias\n",
      "\t features.5.block.2.fc2.weight\n",
      "\t features.5.block.2.fc2.bias\n",
      "\t features.5.block.3.0.weight\n",
      "\t features.5.block.3.1.weight\n",
      "\t features.5.block.3.1.bias\n",
      "\t features.6.block.0.0.weight\n",
      "\t features.6.block.0.1.weight\n",
      "\t features.6.block.0.1.bias\n",
      "\t features.6.block.1.0.weight\n",
      "\t features.6.block.1.1.weight\n",
      "\t features.6.block.1.1.bias\n",
      "\t features.6.block.2.fc1.weight\n",
      "\t features.6.block.2.fc1.bias\n",
      "\t features.6.block.2.fc2.weight\n",
      "\t features.6.block.2.fc2.bias\n",
      "\t features.6.block.3.0.weight\n",
      "\t features.6.block.3.1.weight\n",
      "\t features.6.block.3.1.bias\n",
      "\t features.7.block.0.0.weight\n",
      "\t features.7.block.0.1.weight\n",
      "\t features.7.block.0.1.bias\n",
      "\t features.7.block.1.0.weight\n",
      "\t features.7.block.1.1.weight\n",
      "\t features.7.block.1.1.bias\n",
      "\t features.7.block.2.fc1.weight\n",
      "\t features.7.block.2.fc1.bias\n",
      "\t features.7.block.2.fc2.weight\n",
      "\t features.7.block.2.fc2.bias\n",
      "\t features.7.block.3.0.weight\n",
      "\t features.7.block.3.1.weight\n",
      "\t features.7.block.3.1.bias\n",
      "\t features.8.block.0.0.weight\n",
      "\t features.8.block.0.1.weight\n",
      "\t features.8.block.0.1.bias\n",
      "\t features.8.block.1.0.weight\n",
      "\t features.8.block.1.1.weight\n",
      "\t features.8.block.1.1.bias\n",
      "\t features.8.block.2.fc1.weight\n",
      "\t features.8.block.2.fc1.bias\n",
      "\t features.8.block.2.fc2.weight\n",
      "\t features.8.block.2.fc2.bias\n",
      "\t features.8.block.3.0.weight\n",
      "\t features.8.block.3.1.weight\n",
      "\t features.8.block.3.1.bias\n",
      "\t features.9.block.0.0.weight\n",
      "\t features.9.block.0.1.weight\n",
      "\t features.9.block.0.1.bias\n",
      "\t features.9.block.1.0.weight\n",
      "\t features.9.block.1.1.weight\n",
      "\t features.9.block.1.1.bias\n",
      "\t features.9.block.2.fc1.weight\n",
      "\t features.9.block.2.fc1.bias\n",
      "\t features.9.block.2.fc2.weight\n",
      "\t features.9.block.2.fc2.bias\n",
      "\t features.9.block.3.0.weight\n",
      "\t features.9.block.3.1.weight\n",
      "\t features.9.block.3.1.bias\n",
      "\t features.10.block.0.0.weight\n",
      "\t features.10.block.0.1.weight\n",
      "\t features.10.block.0.1.bias\n",
      "\t features.10.block.1.0.weight\n",
      "\t features.10.block.1.1.weight\n",
      "\t features.10.block.1.1.bias\n",
      "\t features.10.block.2.fc1.weight\n",
      "\t features.10.block.2.fc1.bias\n",
      "\t features.10.block.2.fc2.weight\n",
      "\t features.10.block.2.fc2.bias\n",
      "\t features.10.block.3.0.weight\n",
      "\t features.10.block.3.1.weight\n",
      "\t features.10.block.3.1.bias\n",
      "\t features.11.block.0.0.weight\n",
      "\t features.11.block.0.1.weight\n",
      "\t features.11.block.0.1.bias\n",
      "\t features.11.block.1.0.weight\n",
      "\t features.11.block.1.1.weight\n",
      "\t features.11.block.1.1.bias\n",
      "\t features.11.block.2.fc1.weight\n",
      "\t features.11.block.2.fc1.bias\n",
      "\t features.11.block.2.fc2.weight\n",
      "\t features.11.block.2.fc2.bias\n",
      "\t features.11.block.3.0.weight\n",
      "\t features.11.block.3.1.weight\n",
      "\t features.11.block.3.1.bias\n",
      "\t features.12.0.weight\n",
      "\t features.12.1.weight\n",
      "\t features.12.1.bias\n",
      "\t classifier.0.weight\n",
      "\t classifier.0.bias\n",
      "\t classifier.3.weight\n",
      "\t classifier.3.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:\n",
      "\ttrain loss: 1.9929341233206042\n",
      "\tvalidation loss: 1.392952665890733, validation accuracy: 72.26027397260275%\n",
      "\tElapsed time: 0:06:45.671662\n",
      "Epoch 1:\n",
      "\ttrain loss: 1.2180432101670096\n",
      "\tvalidation loss: 0.7676231844784462, validation accuracy: 88.6986301369863%\n",
      "\tElapsed time: 0:08:25.545917\n",
      "Epoch 2:\n",
      "\ttrain loss: 0.6879486283143634\n",
      "\tvalidation loss: 0.44153117153742544, validation accuracy: 92.46575342465754%\n",
      "\tElapsed time: 0:08:21.811505\n",
      "Epoch 3:\n",
      "\ttrain loss: 0.37251744211026777\n",
      "\tvalidation loss: 0.2954723514514427, validation accuracy: 95.2054794520548%\n",
      "\tElapsed time: 0:05:55.861547\n",
      "Epoch 4:\n",
      "\ttrain loss: 0.20095478018704246\n",
      "\tvalidation loss: 0.2036924072324413, validation accuracy: 96.91780821917808%\n",
      "\tElapsed time: 0:05:04.123045\n",
      "Epoch 5:\n",
      "\ttrain loss: 0.12791535485772285\n",
      "\tvalidation loss: 0.16316360776146796, validation accuracy: 97.94520547945206%\n",
      "\tElapsed time: 0:04:24.493813\n",
      "Epoch 6:\n",
      "\ttrain loss: 0.08070079067252307\n",
      "\tvalidation loss: 0.13308691559997324, validation accuracy: 98.28767123287672%\n",
      "\tElapsed time: 0:04:21.070283\n",
      "Epoch 7:\n",
      "\ttrain loss: 0.05829921207593604\n",
      "\tvalidation loss: 0.11943535516931586, validation accuracy: 98.28767123287672%\n",
      "\tElapsed time: 0:04:22.669784\n",
      "Epoch 8:\n",
      "\ttrain loss: 0.03669489573489229\n",
      "\tvalidation loss: 0.10632954456218302, validation accuracy: 98.63013698630137%\n",
      "\tElapsed time: 0:04:18.534062\n",
      "Epoch 9:\n",
      "\ttrain loss: 0.02796848413197397\n",
      "\tvalidation loss: 0.09915893228903208, validation accuracy: 98.63013698630137%\n",
      "\tElapsed time: 0:04:22.639427\n",
      "Epoch 10:\n",
      "\ttrain loss: 0.021210423678696463\n",
      "\tvalidation loss: 0.09487559881112347, validation accuracy: 98.63013698630137%\n",
      "\tElapsed time: 0:05:03.428517\n",
      "Epoch 11:\n",
      "\ttrain loss: 0.019492519172755154\n",
      "\tvalidation loss: 0.0877902240377583, validation accuracy: 98.28767123287672%\n",
      "\tElapsed time: 0:04:49.463801\n",
      "Epoch 12:\n",
      "\ttrain loss: 0.01493040042550752\n",
      "\tvalidation loss: 0.08520986139774323, validation accuracy: 98.28767123287672%\n",
      "\tElapsed time: 0:04:31.975281\n",
      "Epoch 13:\n",
      "\ttrain loss: 0.013015410800561896\n",
      "\tvalidation loss: 0.07997375050534124, validation accuracy: 98.28767123287672%\n",
      "\tElapsed time: 0:04:24.021548\n",
      "Epoch 14:\n",
      "\ttrain loss: 0.011537194475659375\n",
      "\tvalidation loss: 0.07878001493542161, validation accuracy: 98.28767123287672%\n",
      "\tElapsed time: 0:05:29.960451\n",
      "Epoch 15:\n",
      "\ttrain loss: 0.008178861671180095\n",
      "\tvalidation loss: 0.07717311507320568, validation accuracy: 98.28767123287672%\n",
      "\tElapsed time: 0:04:36.286432\n",
      "Epoch 16:\n",
      "\ttrain loss: 0.008466185693585954\n",
      "\tvalidation loss: 0.07489481237908341, validation accuracy: 98.28767123287672%\n",
      "\tElapsed time: 0:04:24.115548\n",
      "Epoch 17:\n",
      "\ttrain loss: 0.0070174287678753736\n",
      "\tvalidation loss: 0.0738948437142862, validation accuracy: 98.28767123287672%\n",
      "\tElapsed time: 0:04:57.823481\n",
      "Epoch 18:\n",
      "\ttrain loss: 0.006214453913846515\n",
      "\tvalidation loss: 0.07473295110545747, validation accuracy: 97.94520547945206%\n",
      "\tElapsed time: 0:04:29.933094\n",
      "Final loss: 0.0747, final accuracy: 97.95 %\n",
      "\tALBATROSS: 100.00%\n",
      "\tBALD EAGLE: 97.62%\n",
      "\tBARN OWL: 100.00%\n",
      "\tEURASIAN MAGPIE: 96.00%\n",
      "\tFLAMINGO: 100.00%\n",
      "\tMALLARD DUCK: 96.30%\n",
      "\tOSTRICH: 100.00%\n",
      "\tPEACOCK: 100.00%\n",
      "\tPELICAN: 90.00%\n",
      "\tTRUMPTER SWAN: 97.30%\n",
      "Final loss: 0.0747, final accuracy: 97.95 %\n",
      "\tALBATROSS: 100.00%\n",
      "\tBALD EAGLE: 97.62%\n",
      "\tBARN OWL: 100.00%\n",
      "\tEURASIAN MAGPIE: 96.00%\n",
      "\tFLAMINGO: 100.00%\n",
      "\tMALLARD DUCK: 96.30%\n",
      "\tOSTRICH: 100.00%\n",
      "\tPEACOCK: 100.00%\n",
      "\tPELICAN: 90.00%\n",
      "\tTRUMPTER SWAN: 97.30%\n",
      "Training network 4 ...\n",
      "Params to learn:\n",
      "\t features.0.0.weight\n",
      "\t features.0.1.weight\n",
      "\t features.0.1.bias\n",
      "\t features.1.block.0.0.weight\n",
      "\t features.1.block.0.1.weight\n",
      "\t features.1.block.0.1.bias\n",
      "\t features.1.block.1.fc1.weight\n",
      "\t features.1.block.1.fc1.bias\n",
      "\t features.1.block.1.fc2.weight\n",
      "\t features.1.block.1.fc2.bias\n",
      "\t features.1.block.2.0.weight\n",
      "\t features.1.block.2.1.weight\n",
      "\t features.1.block.2.1.bias\n",
      "\t features.2.block.0.0.weight\n",
      "\t features.2.block.0.1.weight\n",
      "\t features.2.block.0.1.bias\n",
      "\t features.2.block.1.0.weight\n",
      "\t features.2.block.1.1.weight\n",
      "\t features.2.block.1.1.bias\n",
      "\t features.2.block.2.0.weight\n",
      "\t features.2.block.2.1.weight\n",
      "\t features.2.block.2.1.bias\n",
      "\t features.3.block.0.0.weight\n",
      "\t features.3.block.0.1.weight\n",
      "\t features.3.block.0.1.bias\n",
      "\t features.3.block.1.0.weight\n",
      "\t features.3.block.1.1.weight\n",
      "\t features.3.block.1.1.bias\n",
      "\t features.3.block.2.0.weight\n",
      "\t features.3.block.2.1.weight\n",
      "\t features.3.block.2.1.bias\n",
      "\t features.4.block.0.0.weight\n",
      "\t features.4.block.0.1.weight\n",
      "\t features.4.block.0.1.bias\n",
      "\t features.4.block.1.0.weight\n",
      "\t features.4.block.1.1.weight\n",
      "\t features.4.block.1.1.bias\n",
      "\t features.4.block.2.fc1.weight\n",
      "\t features.4.block.2.fc1.bias\n",
      "\t features.4.block.2.fc2.weight\n",
      "\t features.4.block.2.fc2.bias\n",
      "\t features.4.block.3.0.weight\n",
      "\t features.4.block.3.1.weight\n",
      "\t features.4.block.3.1.bias\n",
      "\t features.5.block.0.0.weight\n",
      "\t features.5.block.0.1.weight\n",
      "\t features.5.block.0.1.bias\n",
      "\t features.5.block.1.0.weight\n",
      "\t features.5.block.1.1.weight\n",
      "\t features.5.block.1.1.bias\n",
      "\t features.5.block.2.fc1.weight\n",
      "\t features.5.block.2.fc1.bias\n",
      "\t features.5.block.2.fc2.weight\n",
      "\t features.5.block.2.fc2.bias\n",
      "\t features.5.block.3.0.weight\n",
      "\t features.5.block.3.1.weight\n",
      "\t features.5.block.3.1.bias\n",
      "\t features.6.block.0.0.weight\n",
      "\t features.6.block.0.1.weight\n",
      "\t features.6.block.0.1.bias\n",
      "\t features.6.block.1.0.weight\n",
      "\t features.6.block.1.1.weight\n",
      "\t features.6.block.1.1.bias\n",
      "\t features.6.block.2.fc1.weight\n",
      "\t features.6.block.2.fc1.bias\n",
      "\t features.6.block.2.fc2.weight\n",
      "\t features.6.block.2.fc2.bias\n",
      "\t features.6.block.3.0.weight\n",
      "\t features.6.block.3.1.weight\n",
      "\t features.6.block.3.1.bias\n",
      "\t features.7.block.0.0.weight\n",
      "\t features.7.block.0.1.weight\n",
      "\t features.7.block.0.1.bias\n",
      "\t features.7.block.1.0.weight\n",
      "\t features.7.block.1.1.weight\n",
      "\t features.7.block.1.1.bias\n",
      "\t features.7.block.2.fc1.weight\n",
      "\t features.7.block.2.fc1.bias\n",
      "\t features.7.block.2.fc2.weight\n",
      "\t features.7.block.2.fc2.bias\n",
      "\t features.7.block.3.0.weight\n",
      "\t features.7.block.3.1.weight\n",
      "\t features.7.block.3.1.bias\n",
      "\t features.8.block.0.0.weight\n",
      "\t features.8.block.0.1.weight\n",
      "\t features.8.block.0.1.bias\n",
      "\t features.8.block.1.0.weight\n",
      "\t features.8.block.1.1.weight\n",
      "\t features.8.block.1.1.bias\n",
      "\t features.8.block.2.fc1.weight\n",
      "\t features.8.block.2.fc1.bias\n",
      "\t features.8.block.2.fc2.weight\n",
      "\t features.8.block.2.fc2.bias\n",
      "\t features.8.block.3.0.weight\n",
      "\t features.8.block.3.1.weight\n",
      "\t features.8.block.3.1.bias\n",
      "\t features.9.block.0.0.weight\n",
      "\t features.9.block.0.1.weight\n",
      "\t features.9.block.0.1.bias\n",
      "\t features.9.block.1.0.weight\n",
      "\t features.9.block.1.1.weight\n",
      "\t features.9.block.1.1.bias\n",
      "\t features.9.block.2.fc1.weight\n",
      "\t features.9.block.2.fc1.bias\n",
      "\t features.9.block.2.fc2.weight\n",
      "\t features.9.block.2.fc2.bias\n",
      "\t features.9.block.3.0.weight\n",
      "\t features.9.block.3.1.weight\n",
      "\t features.9.block.3.1.bias\n",
      "\t features.10.block.0.0.weight\n",
      "\t features.10.block.0.1.weight\n",
      "\t features.10.block.0.1.bias\n",
      "\t features.10.block.1.0.weight\n",
      "\t features.10.block.1.1.weight\n",
      "\t features.10.block.1.1.bias\n",
      "\t features.10.block.2.fc1.weight\n",
      "\t features.10.block.2.fc1.bias\n",
      "\t features.10.block.2.fc2.weight\n",
      "\t features.10.block.2.fc2.bias\n",
      "\t features.10.block.3.0.weight\n",
      "\t features.10.block.3.1.weight\n",
      "\t features.10.block.3.1.bias\n",
      "\t features.11.block.0.0.weight\n",
      "\t features.11.block.0.1.weight\n",
      "\t features.11.block.0.1.bias\n",
      "\t features.11.block.1.0.weight\n",
      "\t features.11.block.1.1.weight\n",
      "\t features.11.block.1.1.bias\n",
      "\t features.11.block.2.fc1.weight\n",
      "\t features.11.block.2.fc1.bias\n",
      "\t features.11.block.2.fc2.weight\n",
      "\t features.11.block.2.fc2.bias\n",
      "\t features.11.block.3.0.weight\n",
      "\t features.11.block.3.1.weight\n",
      "\t features.11.block.3.1.bias\n",
      "\t features.12.0.weight\n",
      "\t features.12.1.weight\n",
      "\t features.12.1.bias\n",
      "\t classifier.0.weight\n",
      "\t classifier.0.bias\n",
      "\t classifier.3.weight\n",
      "\t classifier.3.bias\n",
      "Epoch 0:\n",
      "\ttrain loss: 1.9646178506455332\n",
      "\tvalidation loss: 1.4452956294360226, validation accuracy: 73.28767123287672%\n",
      "\tElapsed time: 0:04:30.732153\n",
      "Epoch 1:\n",
      "\ttrain loss: 1.15384726683844\n",
      "\tvalidation loss: 0.7926725859511389, validation accuracy: 85.61643835616438%\n",
      "\tElapsed time: 0:04:26.426885\n",
      "Epoch 2:\n",
      "\ttrain loss: 0.6343458002468325\n",
      "\tvalidation loss: 0.4613708812896519, validation accuracy: 90.75342465753424%\n",
      "\tElapsed time: 0:04:22.754882\n",
      "Epoch 3:\n",
      "\ttrain loss: 0.3536498732161972\n",
      "\tvalidation loss: 0.3118633025721328, validation accuracy: 93.4931506849315%\n",
      "\tElapsed time: 0:04:23.532902\n",
      "Epoch 4:\n",
      "\ttrain loss: 0.19746050187490408\n",
      "\tvalidation loss: 0.22084279297149345, validation accuracy: 96.57534246575342%\n",
      "\tElapsed time: 0:04:50.317446\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5:\n",
      "\ttrain loss: 0.12290272970346808\n",
      "\tvalidation loss: 0.1739437659717586, validation accuracy: 97.26027397260275%\n",
      "\tElapsed time: 0:05:39.688167\n",
      "Epoch 6:\n",
      "\ttrain loss: 0.08184558061138435\n",
      "\tvalidation loss: 0.1437285109742047, validation accuracy: 97.6027397260274%\n",
      "\tElapsed time: 0:04:34.248815\n",
      "Epoch 7:\n",
      "\ttrain loss: 0.05727545697222852\n",
      "\tvalidation loss: 0.12375886483143454, validation accuracy: 98.28767123287672%\n",
      "\tElapsed time: 0:04:27.569147\n",
      "Epoch 8:\n",
      "\ttrain loss: 0.039900653409303564\n",
      "\tvalidation loss: 0.11254085100268664, validation accuracy: 98.28767123287672%\n",
      "\tElapsed time: 0:04:45.784091\n",
      "Epoch 9:\n",
      "\ttrain loss: 0.026639219686567885\n",
      "\tvalidation loss: 0.10904577823534403, validation accuracy: 98.28767123287672%\n",
      "\tElapsed time: 0:04:28.771724\n",
      "Epoch 10:\n",
      "\ttrain loss: 0.024728202467103767\n",
      "\tvalidation loss: 0.10391525362860667, validation accuracy: 97.94520547945206%\n",
      "\tElapsed time: 0:04:23.710611\n",
      "Epoch 11:\n",
      "\ttrain loss: 0.016230694463997313\n",
      "\tvalidation loss: 0.0993338017022773, validation accuracy: 97.6027397260274%\n",
      "\tElapsed time: 0:04:23.013938\n",
      "Epoch 12:\n",
      "\ttrain loss: 0.014107741179075699\n",
      "\tvalidation loss: 0.09871281530350855, validation accuracy: 97.26027397260275%\n",
      "\tElapsed time: 0:04:22.530593\n",
      "Epoch 13:\n",
      "\ttrain loss: 0.011751166351561277\n",
      "\tvalidation loss: 0.09461810215287013, validation accuracy: 97.26027397260275%\n",
      "\tElapsed time: 0:04:18.626194\n",
      "Epoch 14:\n",
      "\ttrain loss: 0.010284524560326113\n",
      "\tvalidation loss: 0.09319222596001951, validation accuracy: 97.6027397260274%\n",
      "\tElapsed time: 0:04:18.606733\n",
      "Epoch 15:\n",
      "\ttrain loss: 0.008530533807048667\n",
      "\tvalidation loss: 0.09060748411368018, validation accuracy: 97.6027397260274%\n",
      "\tElapsed time: 0:04:19.360952\n",
      "Epoch 16:\n",
      "\ttrain loss: 0.00787459272335365\n",
      "\tvalidation loss: 0.09008952975273132, validation accuracy: 97.26027397260275%\n",
      "\tElapsed time: 0:04:17.889705\n",
      "Epoch 17:\n",
      "\ttrain loss: 0.006828053482196343\n",
      "\tvalidation loss: 0.0812754723919581, validation accuracy: 98.28767123287672%\n",
      "\tElapsed time: 0:04:18.431027\n",
      "Final loss: 0.0813, final accuracy: 98.29 %\n",
      "\tALBATROSS: 92.86%\n",
      "\tBALD EAGLE: 97.73%\n",
      "\tBARN OWL: 100.00%\n",
      "\tEURASIAN MAGPIE: 100.00%\n",
      "\tFLAMINGO: 100.00%\n",
      "\tMALLARD DUCK: 94.59%\n",
      "\tOSTRICH: 100.00%\n",
      "\tPEACOCK: 100.00%\n",
      "\tPELICAN: 100.00%\n",
      "\tTRUMPTER SWAN: 100.00%\n",
      "Final loss: 0.0813, final accuracy: 98.29 %\n",
      "\tALBATROSS: 92.86%\n",
      "\tBALD EAGLE: 97.73%\n",
      "\tBARN OWL: 100.00%\n",
      "\tEURASIAN MAGPIE: 100.00%\n",
      "\tFLAMINGO: 100.00%\n",
      "\tMALLARD DUCK: 94.59%\n",
      "\tOSTRICH: 100.00%\n",
      "\tPEACOCK: 100.00%\n",
      "\tPELICAN: 100.00%\n",
      "\tTRUMPTER SWAN: 100.00%\n",
      "Training network 5 ...\n",
      "Params to learn:\n",
      "\t features.0.0.weight\n",
      "\t features.0.1.weight\n",
      "\t features.0.1.bias\n",
      "\t features.1.block.0.0.weight\n",
      "\t features.1.block.0.1.weight\n",
      "\t features.1.block.0.1.bias\n",
      "\t features.1.block.1.fc1.weight\n",
      "\t features.1.block.1.fc1.bias\n",
      "\t features.1.block.1.fc2.weight\n",
      "\t features.1.block.1.fc2.bias\n",
      "\t features.1.block.2.0.weight\n",
      "\t features.1.block.2.1.weight\n",
      "\t features.1.block.2.1.bias\n",
      "\t features.2.block.0.0.weight\n",
      "\t features.2.block.0.1.weight\n",
      "\t features.2.block.0.1.bias\n",
      "\t features.2.block.1.0.weight\n",
      "\t features.2.block.1.1.weight\n",
      "\t features.2.block.1.1.bias\n",
      "\t features.2.block.2.0.weight\n",
      "\t features.2.block.2.1.weight\n",
      "\t features.2.block.2.1.bias\n",
      "\t features.3.block.0.0.weight\n",
      "\t features.3.block.0.1.weight\n",
      "\t features.3.block.0.1.bias\n",
      "\t features.3.block.1.0.weight\n",
      "\t features.3.block.1.1.weight\n",
      "\t features.3.block.1.1.bias\n",
      "\t features.3.block.2.0.weight\n",
      "\t features.3.block.2.1.weight\n",
      "\t features.3.block.2.1.bias\n",
      "\t features.4.block.0.0.weight\n",
      "\t features.4.block.0.1.weight\n",
      "\t features.4.block.0.1.bias\n",
      "\t features.4.block.1.0.weight\n",
      "\t features.4.block.1.1.weight\n",
      "\t features.4.block.1.1.bias\n",
      "\t features.4.block.2.fc1.weight\n",
      "\t features.4.block.2.fc1.bias\n",
      "\t features.4.block.2.fc2.weight\n",
      "\t features.4.block.2.fc2.bias\n",
      "\t features.4.block.3.0.weight\n",
      "\t features.4.block.3.1.weight\n",
      "\t features.4.block.3.1.bias\n",
      "\t features.5.block.0.0.weight\n",
      "\t features.5.block.0.1.weight\n",
      "\t features.5.block.0.1.bias\n",
      "\t features.5.block.1.0.weight\n",
      "\t features.5.block.1.1.weight\n",
      "\t features.5.block.1.1.bias\n",
      "\t features.5.block.2.fc1.weight\n",
      "\t features.5.block.2.fc1.bias\n",
      "\t features.5.block.2.fc2.weight\n",
      "\t features.5.block.2.fc2.bias\n",
      "\t features.5.block.3.0.weight\n",
      "\t features.5.block.3.1.weight\n",
      "\t features.5.block.3.1.bias\n",
      "\t features.6.block.0.0.weight\n",
      "\t features.6.block.0.1.weight\n",
      "\t features.6.block.0.1.bias\n",
      "\t features.6.block.1.0.weight\n",
      "\t features.6.block.1.1.weight\n",
      "\t features.6.block.1.1.bias\n",
      "\t features.6.block.2.fc1.weight\n",
      "\t features.6.block.2.fc1.bias\n",
      "\t features.6.block.2.fc2.weight\n",
      "\t features.6.block.2.fc2.bias\n",
      "\t features.6.block.3.0.weight\n",
      "\t features.6.block.3.1.weight\n",
      "\t features.6.block.3.1.bias\n",
      "\t features.7.block.0.0.weight\n",
      "\t features.7.block.0.1.weight\n",
      "\t features.7.block.0.1.bias\n",
      "\t features.7.block.1.0.weight\n",
      "\t features.7.block.1.1.weight\n",
      "\t features.7.block.1.1.bias\n",
      "\t features.7.block.2.fc1.weight\n",
      "\t features.7.block.2.fc1.bias\n",
      "\t features.7.block.2.fc2.weight\n",
      "\t features.7.block.2.fc2.bias\n",
      "\t features.7.block.3.0.weight\n",
      "\t features.7.block.3.1.weight\n",
      "\t features.7.block.3.1.bias\n",
      "\t features.8.block.0.0.weight\n",
      "\t features.8.block.0.1.weight\n",
      "\t features.8.block.0.1.bias\n",
      "\t features.8.block.1.0.weight\n",
      "\t features.8.block.1.1.weight\n",
      "\t features.8.block.1.1.bias\n",
      "\t features.8.block.2.fc1.weight\n",
      "\t features.8.block.2.fc1.bias\n",
      "\t features.8.block.2.fc2.weight\n",
      "\t features.8.block.2.fc2.bias\n",
      "\t features.8.block.3.0.weight\n",
      "\t features.8.block.3.1.weight\n",
      "\t features.8.block.3.1.bias\n",
      "\t features.9.block.0.0.weight\n",
      "\t features.9.block.0.1.weight\n",
      "\t features.9.block.0.1.bias\n",
      "\t features.9.block.1.0.weight\n",
      "\t features.9.block.1.1.weight\n",
      "\t features.9.block.1.1.bias\n",
      "\t features.9.block.2.fc1.weight\n",
      "\t features.9.block.2.fc1.bias\n",
      "\t features.9.block.2.fc2.weight\n",
      "\t features.9.block.2.fc2.bias\n",
      "\t features.9.block.3.0.weight\n",
      "\t features.9.block.3.1.weight\n",
      "\t features.9.block.3.1.bias\n",
      "\t features.10.block.0.0.weight\n",
      "\t features.10.block.0.1.weight\n",
      "\t features.10.block.0.1.bias\n",
      "\t features.10.block.1.0.weight\n",
      "\t features.10.block.1.1.weight\n",
      "\t features.10.block.1.1.bias\n",
      "\t features.10.block.2.fc1.weight\n",
      "\t features.10.block.2.fc1.bias\n",
      "\t features.10.block.2.fc2.weight\n",
      "\t features.10.block.2.fc2.bias\n",
      "\t features.10.block.3.0.weight\n",
      "\t features.10.block.3.1.weight\n",
      "\t features.10.block.3.1.bias\n",
      "\t features.11.block.0.0.weight\n",
      "\t features.11.block.0.1.weight\n",
      "\t features.11.block.0.1.bias\n",
      "\t features.11.block.1.0.weight\n",
      "\t features.11.block.1.1.weight\n",
      "\t features.11.block.1.1.bias\n",
      "\t features.11.block.2.fc1.weight\n",
      "\t features.11.block.2.fc1.bias\n",
      "\t features.11.block.2.fc2.weight\n",
      "\t features.11.block.2.fc2.bias\n",
      "\t features.11.block.3.0.weight\n",
      "\t features.11.block.3.1.weight\n",
      "\t features.11.block.3.1.bias\n",
      "\t features.12.0.weight\n",
      "\t features.12.1.weight\n",
      "\t features.12.1.bias\n",
      "\t classifier.0.weight\n",
      "\t classifier.0.bias\n",
      "\t classifier.3.weight\n",
      "\t classifier.3.bias\n",
      "Epoch 0:\n",
      "\ttrain loss: 2.0033794866417938\n",
      "\tvalidation loss: 1.4454992993237221, validation accuracy: 78.42465753424658%\n",
      "\tElapsed time: 0:04:17.813096\n",
      "Epoch 1:\n",
      "\ttrain loss: 1.2031967273911726\n",
      "\tvalidation loss: 0.805146626413685, validation accuracy: 87.32876712328768%\n",
      "\tElapsed time: 0:04:18.519187\n",
      "Epoch 2:\n",
      "\ttrain loss: 0.6758276539028816\n",
      "\tvalidation loss: 0.46130632700985424, validation accuracy: 93.15068493150685%\n",
      "\tElapsed time: 0:04:19.218729\n",
      "Epoch 3:\n",
      "\ttrain loss: 0.37274687004948154\n",
      "\tvalidation loss: 0.302290822545143, validation accuracy: 94.86301369863014%\n",
      "\tElapsed time: 0:04:33.574421\n",
      "Epoch 4:\n",
      "\ttrain loss: 0.21344499491909152\n",
      "\tvalidation loss: 0.22644226212207585, validation accuracy: 97.26027397260275%\n",
      "\tElapsed time: 0:04:28.508105\n",
      "Epoch 5:\n",
      "\ttrain loss: 0.13504867176453408\n",
      "\tvalidation loss: 0.17401923280056208, validation accuracy: 97.94520547945206%\n",
      "\tElapsed time: 0:04:25.582387\n",
      "Epoch 6:\n",
      "\ttrain loss: 0.09668374225164973\n",
      "\tvalidation loss: 0.1457119102347387, validation accuracy: 98.28767123287672%\n",
      "\tElapsed time: 0:04:24.428196\n",
      "Epoch 7:\n",
      "\ttrain loss: 0.05593079865285504\n",
      "\tvalidation loss: 0.12803929595098104, validation accuracy: 98.28767123287672%\n",
      "\tElapsed time: 0:04:21.210052\n",
      "Epoch 8:\n",
      "\ttrain loss: 0.039865912412697414\n",
      "\tvalidation loss: 0.11455926574664572, validation accuracy: 98.63013698630137%\n",
      "\tElapsed time: 0:04:21.415278\n",
      "Epoch 9:\n",
      "\ttrain loss: 0.028405710083542722\n",
      "\tvalidation loss: 0.10609944664860425, validation accuracy: 98.63013698630137%\n",
      "\tElapsed time: 0:04:22.853987\n",
      "Epoch 10:\n",
      "\ttrain loss: 0.023541541108749744\n",
      "\tvalidation loss: 0.09885917706032323, validation accuracy: 98.63013698630137%\n",
      "\tElapsed time: 0:04:21.596392\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11:\n",
      "\ttrain loss: 0.02061658953899585\n",
      "\tvalidation loss: 0.09717612233880447, validation accuracy: 98.63013698630137%\n",
      "\tElapsed time: 0:04:21.628353\n",
      "Epoch 12:\n",
      "\ttrain loss: 0.012925076935804525\n",
      "\tvalidation loss: 0.09267537969432466, validation accuracy: 98.28767123287672%\n",
      "\tElapsed time: 0:04:21.536228\n",
      "Epoch 13:\n",
      "\ttrain loss: 0.012185501008203467\n",
      "\tvalidation loss: 0.08861031916553844, validation accuracy: 98.28767123287672%\n",
      "\tElapsed time: 0:04:21.996523\n",
      "Epoch 14:\n",
      "\ttrain loss: 0.010077191753181954\n",
      "\tvalidation loss: 0.08698046942279763, validation accuracy: 98.63013698630137%\n",
      "\tElapsed time: 0:04:22.039663\n",
      "Epoch 15:\n",
      "\ttrain loss: 0.010803324421212767\n",
      "\tvalidation loss: 0.08554843088535413, validation accuracy: 98.63013698630137%\n",
      "\tElapsed time: 0:04:22.204544\n",
      "Epoch 16:\n",
      "\ttrain loss: 0.007335213356448487\n",
      "\tvalidation loss: 0.08847868340472652, validation accuracy: 98.63013698630137%\n",
      "\tElapsed time: 0:04:21.913419\n",
      "Epoch 17:\n",
      "\ttrain loss: 0.006231150377420373\n",
      "\tvalidation loss: 0.08688600004127581, validation accuracy: 98.63013698630137%\n",
      "\tElapsed time: 0:04:22.385084\n",
      "Epoch 18:\n",
      "\ttrain loss: 0.004831647046715481\n",
      "\tvalidation loss: 0.08541495332570925, validation accuracy: 98.63013698630137%\n",
      "\tElapsed time: 0:45:00.228620\n",
      "Final loss: 0.0854, final accuracy: 98.63 %\n",
      "\tALBATROSS: 96.97%\n",
      "\tBALD EAGLE: 100.00%\n",
      "\tBARN OWL: 100.00%\n",
      "\tEURASIAN MAGPIE: 100.00%\n",
      "\tFLAMINGO: 100.00%\n",
      "\tMALLARD DUCK: 100.00%\n",
      "\tOSTRICH: 100.00%\n",
      "\tPEACOCK: 100.00%\n",
      "\tPELICAN: 96.30%\n",
      "\tTRUMPTER SWAN: 93.94%\n",
      "Final loss: 0.0854, final accuracy: 98.63 %\n",
      "\tALBATROSS: 96.97%\n",
      "\tBALD EAGLE: 100.00%\n",
      "\tBARN OWL: 100.00%\n",
      "\tEURASIAN MAGPIE: 100.00%\n",
      "\tFLAMINGO: 100.00%\n",
      "\tMALLARD DUCK: 100.00%\n",
      "\tOSTRICH: 100.00%\n",
      "\tPEACOCK: 100.00%\n",
      "\tPELICAN: 96.30%\n",
      "\tTRUMPTER SWAN: 93.94%\n",
      "Losses:  [0.08435911741362859, 0.034117446064132535, 0.07473295212608494, 0.08127546463518927, 0.08541495648965444]\n",
      "Loss:  mean: 0.0720, std: 0.0216\n",
      "Accuracies:  [0.9726027397260274, 0.9897260273972602, 0.9794520547945206, 0.9828767123287672, 0.9863013698630136]\n",
      "Accuracy:  mean: 0.9822, std: 0.0066\n"
     ]
    }
   ],
   "source": [
    "dataset_dir = \"../data/birds270\"\n",
    "selected_birds = [\"ALBATROSS\", \"BALD EAGLE\", \"BARN OWL\", \"EURASIAN MAGPIE\", \"FLAMINGO\",\n",
    "                  \"MALLARD DUCK\", \"OSTRICH\", \"PEACOCK\", \"PELICAN\", \"TRUMPTER SWAN\"]\n",
    "\n",
    "#transform = transforms.Normalize((127.5, 127.5, 127.5), (127.5, 127.5, 127.5)) # normalizes colors to range [-1,1]\n",
    "transform =  transforms.Compose([\n",
    "    transforms.Normalize((0, 0, 0), (255, 255, 255)),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "dataset = Birds270Dataset(dataset_dir,  selected_birds=selected_birds, transform=transform)\n",
    "\n",
    "def net_generator():\n",
    "    return make_mobilenet_v3(out_features=len(selected_birds), feature_extract = False)\n",
    "\n",
    "results = cross_validate_net(net_generator, dataset, repeat=5, epochs=100, batch_size=64)\n",
    "print_validation_results(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a338172",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = results_to_dataframe(results)\n",
    "dataframe.to_csv(\"../results/mobilenet_v3_small_pretrained.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1547d404",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
